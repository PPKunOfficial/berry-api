# Berry API Configuration File
# This is a basic configuration example

[settings]
health_check_interval_seconds = 30
request_timeout_seconds = 30
max_retries = 3
circuit_breaker_failure_threshold = 5
circuit_breaker_timeout_seconds = 60
recovery_check_interval_seconds = 120
max_internal_retries = 2
health_check_timeout_seconds = 10

[settings.smart_ai]
enabled = false
small_traffic_threshold = 100
cost_control_factor = 0.8
health_check_weight = 0.3

# Provider Configuration
[providers.openai]
name = "OpenAI"
base_url = "https://api.openai.com"
api_key = "your-openai-api-key-here"
models = ["gpt-3.5-turbo", "gpt-4"]
enabled = true
timeout_seconds = 30
max_retries = 3
backend_type = "OpenAI"

[providers.anthropic]
name = "Anthropic"
base_url = "https://api.anthropic.com"
api_key = "your-anthropic-api-key-here"
models = ["claude-3-sonnet-20240229"]
enabled = true
timeout_seconds = 30
max_retries = 3
backend_type = "OpenAI"

# Model Mappings
[models.gpt-3_5-turbo]
name = "gpt-3.5-turbo"
enabled = true
strategy = "WeightedRandom"

[[models.gpt-3_5-turbo.backends]]
provider = "openai"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 1
enabled = true
billing_mode = "PerToken"

[models.claude-3-sonnet]
name = "claude-3-sonnet"
enabled = true
strategy = "WeightedRandom"

[[models.claude-3-sonnet.backends]]
provider = "anthropic"
model = "claude-3-sonnet-20240229"
weight = 1.0
priority = 1
enabled = true
billing_mode = "PerToken"

# User Configuration
[users.user1]
token = "your-user-token-here"
enabled = true
models = ["gpt-3.5-turbo", "claude-3-sonnet"]
