# Berry API - æ™ºèƒ½AIè´Ÿè½½å‡è¡¡ç½‘å…³

[![Rust](https://img.shields.io/badge/rust-1.70+-orange.svg)](https://www.rust-lang.org)
[![License](https://img.shields.io/badge/license-GPL--3.0-blue.svg)](LICENSE)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](Dockerfile)
[![OpenAI Compatible](https://img.shields.io/badge/OpenAI-Compatible-green.svg)](https://platform.openai.com/docs/api-reference)

Berry API æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½ã€ç”Ÿäº§å°±ç»ªçš„AIæœåŠ¡è´Ÿè½½å‡è¡¡ç½‘å…³ï¼Œä¸“ä¸ºå¤šAIæä¾›å•†ç¯å¢ƒè®¾è®¡ã€‚å®ƒæä¾›æ™ºèƒ½è´Ÿè½½å‡è¡¡ã€è‡ªåŠ¨æ•…éšœè½¬ç§»ã€å¥åº·æ£€æŸ¥å’Œæˆæœ¬ä¼˜åŒ–åŠŸèƒ½ï¼Œå®Œå…¨å…¼å®¹OpenAI APIæ ¼å¼ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### ğŸ¯ æ™ºèƒ½è´Ÿè½½å‡è¡¡
- **8ç§è´Ÿè½½å‡è¡¡ç­–ç•¥**ï¼šåŠ æƒéšæœºã€è½®è¯¢ã€æœ€ä½å»¶è¿Ÿã€æ•…éšœè½¬ç§»ã€SmartAIç­‰
- **SmartAIç­–ç•¥**ï¼šåŸºäºæˆæœ¬æ„ŸçŸ¥çš„æ™ºèƒ½é€‰æ‹©ï¼Œå°æµé‡å¥åº·æ£€æŸ¥ä¼˜åŒ–
- **æƒé‡æ•…éšœè½¬ç§»**ï¼šç»“åˆæƒé‡åˆ†é…å’Œè‡ªåŠ¨æ•…éšœåˆ‡æ¢
- **ç”¨æˆ·æ ‡ç­¾è¿‡æ»¤**ï¼šæ”¯æŒåŸºäºç”¨æˆ·æ ‡ç­¾çš„åç«¯é€‰æ‹©

### ğŸ¥ æ™ºèƒ½å¥åº·æ£€æŸ¥
- **å·®å¼‚åŒ–æ£€æŸ¥ç­–ç•¥**ï¼šæŒ‰tokenè®¡è´¹æ‰§è¡Œä¸»åŠ¨æ£€æŸ¥ï¼ŒæŒ‰è¯·æ±‚è®¡è´¹ä½¿ç”¨è¢«åŠ¨éªŒè¯
- **è‡ªåŠ¨æ•…éšœæ¢å¤**ï¼šæ”¯æŒæ¸è¿›å¼æƒé‡æ¢å¤ï¼ˆ30%â†’50%â†’100%ï¼‰
- **ç†”æ–­æœºåˆ¶**ï¼šè‡ªåŠ¨ç†”æ–­æ•…éšœæœåŠ¡ï¼Œé˜²æ­¢çº§è”å¤±è´¥
- **å®æ—¶ç›‘æ§**ï¼šæä¾›è¯¦ç»†çš„å¥åº·çŠ¶æ€å’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ” ä¼ä¸šçº§è®¤è¯
- **Tokenè®¤è¯**ï¼šåŸºäºBearer Tokençš„ç”¨æˆ·è®¤è¯
- **æƒé™æ§åˆ¶**ï¼šç»†ç²’åº¦çš„æ¨¡å‹è®¿é—®æƒé™ç®¡ç†
- **é€Ÿç‡é™åˆ¶**ï¼šæ”¯æŒç”¨æˆ·çº§åˆ«çš„è¯·æ±‚é¢‘ç‡æ§åˆ¶
- **ç”¨æˆ·æ ‡ç­¾**ï¼šæ”¯æŒç”¨æˆ·åˆ†ç»„å’Œæƒé™æ ‡ç­¾

### ğŸš€ é«˜æ€§èƒ½æ¶æ„
- **å¼‚æ­¥å¤„ç†**ï¼šåŸºäºTokioçš„é«˜å¹¶å‘å¼‚æ­¥æ¶æ„
- **æµå¼æ”¯æŒ**ï¼šå®Œæ•´æ”¯æŒSSEæµå¼å’Œéæµå¼å“åº”
- **è¿æ¥ä¿æ´»**ï¼šæ™ºèƒ½ä¿æ´»æœºåˆ¶é˜²æ­¢è¿æ¥è¶…æ—¶
- **é…ç½®çƒ­é‡è½½**ï¼šè¿è¡Œæ—¶é…ç½®æ›´æ–°ï¼Œæ— éœ€é‡å¯æœåŠ¡

### ğŸ“Š å¯è§‚æµ‹æ€§
- **PrometheusæŒ‡æ ‡**ï¼šå®Œæ•´çš„æ€§èƒ½å’Œå¥åº·æŒ‡æ ‡å¯¼å‡º
- **ç»“æ„åŒ–æ—¥å¿—**ï¼šæ”¯æŒå¤šçº§åˆ«æ—¥å¿—å’Œè°ƒè¯•æ¨¡å¼
- **å¥åº·æ£€æŸ¥ç«¯ç‚¹**ï¼šæä¾›è¯¦ç»†çš„æœåŠ¡çŠ¶æ€ä¿¡æ¯
- **ç®¡ç†API**ï¼šä¸°å¯Œçš„ç®¡ç†å’Œç›‘æ§æ¥å£

## ğŸ“š æ–‡æ¡£å¯¼èˆª

### ğŸš€ å¿«é€Ÿå¼€å§‹
- **[âš¡ å¿«é€Ÿå¼€å§‹æŒ‡å—](QUICKSTART.md)** - 5åˆ†é’Ÿéƒ¨ç½²è¿è¡Œ
- **[ğŸ³ Dockeréƒ¨ç½²](#-dockeréƒ¨ç½²)** - å®¹å™¨åŒ–éƒ¨ç½²æ–¹æ¡ˆ
- **[âš™ï¸ é…ç½®æŒ‡å—](#-é…ç½®æŒ‡å—)** - è¯¦ç»†é…ç½®è¯´æ˜

### ğŸ“– ä½¿ç”¨æŒ‡å—
- **[ğŸ”Œ APIå‚è€ƒæ–‡æ¡£](API_REFERENCE.md)** - å®Œæ•´çš„APIæ¥å£æ–‡æ¡£
- **[ğŸ¥ å¥åº·æ£€æŸ¥](#-å¥åº·æ£€æŸ¥ä¸æ•…éšœå¤„ç†)** - å¥åº·æ£€æŸ¥æœºåˆ¶è¯¦è§£
- **[âš–ï¸ è´Ÿè½½å‡è¡¡](#-è´Ÿè½½å‡è¡¡ç­–ç•¥è¯¦è§£)** - è´Ÿè½½å‡è¡¡ç­–ç•¥é€‰æ‹©
- **[ğŸ” è®¤è¯æˆæƒ](#-è®¤è¯ä¸æƒé™ç®¡ç†)** - ç”¨æˆ·è®¤è¯å’Œæƒé™é…ç½®

### ğŸ› ï¸ è¿ç»´æŒ‡å—
- **[ğŸ“Š ç›‘æ§å‘Šè­¦](#-ç›‘æ§ä¸å¯è§‚æµ‹æ€§)** - ç›‘æ§æŒ‡æ ‡å’Œå‘Šè­¦é…ç½®
- **[ğŸ”§ æ•…éšœæ’é™¤](#-æ•…éšœæ’é™¤)** - å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
- **[ğŸ¯ æ€§èƒ½ä¼˜åŒ–](#-æ€§èƒ½ä¼˜åŒ–)** - æ€§èƒ½è°ƒä¼˜å»ºè®®
- **[ğŸ”„ é…ç½®ç®¡ç†](#-é…ç½®çƒ­é‡è½½)** - é…ç½®çƒ­é‡è½½å’Œç®¡ç†

### ğŸ—ï¸ å¼€å‘æŒ‡å—
- **[ğŸ›ï¸ æ¶æ„è®¾è®¡](ARCHITECTURE.md)** - ç³»ç»Ÿæ¶æ„å’Œç»„ä»¶è®¾è®¡
- **[ğŸ§ª æµ‹è¯•æŒ‡å—](#-æµ‹è¯•ä¸è°ƒè¯•)** - æµ‹è¯•å’Œè°ƒè¯•æ–¹æ³•
- **[ğŸ¤ è´¡çŒ®æŒ‡å—](#-è´¡çŒ®æŒ‡å—)** - å¼€å‘ç¯å¢ƒå’Œè´¡çŒ®æµç¨‹

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

Berry API é‡‡ç”¨æ¨¡å—åŒ–æ¶æ„è®¾è®¡ï¼Œç”±5ä¸ªæ ¸å¿ƒæ¨¡å—ç»„æˆï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Berry API Gateway                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   berry-api     â”‚  berry-relay    â”‚ berry-loadbalanceâ”‚berry-core â”‚
â”‚   WebæœåŠ¡å±‚     â”‚   è¯·æ±‚è½¬å‘å±‚    â”‚   è´Ÿè½½å‡è¡¡å±‚     â”‚  æ ¸å¿ƒåº“   â”‚
â”‚                 â”‚                 â”‚                 â”‚           â”‚
â”‚ â€¢ HTTPè·¯ç”±      â”‚ â€¢ è¯·æ±‚è½¬å‘      â”‚ â€¢ åç«¯é€‰æ‹©      â”‚ â€¢ é…ç½®ç®¡ç†â”‚
â”‚ â€¢ è®¤è¯ä¸­é—´ä»¶    â”‚ â€¢ æµå¼å¤„ç†      â”‚ â€¢ å¥åº·æ£€æŸ¥      â”‚ â€¢ è®¤è¯ç³»ç»Ÿâ”‚
â”‚ â€¢ é™æ€æ–‡ä»¶      â”‚ â€¢ é”™è¯¯å¤„ç†      â”‚ â€¢ æŒ‡æ ‡æ”¶é›†      â”‚ â€¢ å…±äº«ç±»å‹â”‚
â”‚ â€¢ ç®¡ç†æ¥å£      â”‚ â€¢ åè®®é€‚é…      â”‚ â€¢ ç­–ç•¥å®ç°      â”‚ â€¢ å·¥å…·å‡½æ•°â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      berry-cli        â”‚
                    â”‚     å‘½ä»¤è¡Œå·¥å…·        â”‚
                    â”‚                       â”‚
                    â”‚ â€¢ é…ç½®éªŒè¯            â”‚
                    â”‚ â€¢ å¥åº·æ£€æŸ¥            â”‚
                    â”‚ â€¢ æŒ‡æ ‡æŸ¥çœ‹            â”‚
                    â”‚ â€¢ åç«¯æµ‹è¯•            â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ è¯·æ±‚å¤„ç†æµç¨‹

```mermaid
graph TD
    A[å®¢æˆ·ç«¯è¯·æ±‚] --> B[è®¤è¯ä¸­é—´ä»¶]
    B --> C{è®¤è¯æˆåŠŸ?}
    C -->|å¦| D[è¿”å›401é”™è¯¯]
    C -->|æ˜¯| E[æƒé™æ£€æŸ¥]
    E --> F{æœ‰æƒé™?}
    F -->|å¦| G[è¿”å›403é”™è¯¯]
    F -->|æ˜¯| H[é€Ÿç‡é™åˆ¶æ£€æŸ¥]
    H --> I{æœªè¶…é™?}
    I -->|å¦| J[è¿”å›429é”™è¯¯]
    I -->|æ˜¯| K[è´Ÿè½½å‡è¡¡é€‰æ‹©]
    K --> L[åç«¯å¥åº·æ£€æŸ¥]
    L --> M{åç«¯å¥åº·?}
    M -->|å¦| N[é‡è¯•å…¶ä»–åç«¯]
    M -->|æ˜¯| O[è½¬å‘è¯·æ±‚]
    O --> P[å¤„ç†å“åº”]
    P --> Q{æµå¼å“åº”?}
    Q -->|æ˜¯| R[SSEæµå¼ä¼ è¾“]
    Q -->|å¦| S[JSONå“åº”]
    R --> T[è¿”å›å®¢æˆ·ç«¯]
    S --> T
    N --> K
```

### ğŸ§© æ ¸å¿ƒç»„ä»¶

| ç»„ä»¶ | åŠŸèƒ½ | æŠ€æœ¯æ ˆ |
|------|------|--------|
| **berry-api** | WebæœåŠ¡å±‚ï¼Œæä¾›HTTP API | Axum, Tower |
| **berry-relay** | è¯·æ±‚è½¬å‘å±‚ï¼Œå¤„ç†ä¸Šæ¸¸è¯·æ±‚ | Reqwest, Tokio |
| **berry-loadbalance** | è´Ÿè½½å‡è¡¡å±‚ï¼Œå®ç°é€‰æ‹©ç­–ç•¥ | è‡ªç ”ç®—æ³•, Metrics |
| **berry-core** | æ ¸å¿ƒåº“ï¼Œé…ç½®å’Œè®¤è¯ç®¡ç† | Serde, TOML |
| **berry-cli** | å‘½ä»¤è¡Œå·¥å…·ï¼Œè¿ç»´ç®¡ç† | Clap, é…ç½®éªŒè¯ |

## âš–ï¸ è´Ÿè½½å‡è¡¡ç­–ç•¥

Berry API æä¾›8ç§è´Ÿè½½å‡è¡¡ç­–ç•¥ï¼Œé€‚åº”ä¸åŒçš„ä¸šåŠ¡åœºæ™¯ï¼š

| ç­–ç•¥ | é€‚ç”¨åœºæ™¯ | ä¼˜åŠ¿ | é…ç½®å¤æ‚åº¦ |
|------|----------|------|------------|
| `weighted_random` | æˆæœ¬æ§åˆ¶ã€æŒ‰æ€§èƒ½åˆ†é… | çµæ´»çš„æƒé‡åˆ†é… | â­â­ |
| `round_robin` | ç®€å•å‡è¡¡ã€ç›¸åŒæ€§èƒ½åç«¯ | å®Œå…¨å‡åŒ€åˆ†é… | â­ |
| `least_latency` | æ€§èƒ½ä¼˜åŒ–ã€å»¶è¿Ÿæ•æ„Ÿ | è‡ªåŠ¨é€‰æ‹©æœ€å¿«åç«¯ | â­â­ |
| `failover` | é«˜å¯ç”¨ã€ä¸»å¤‡åœºæ™¯ | æ˜ç¡®çš„ä¼˜å…ˆçº§ | â­â­ |
| `weighted_failover` | æ™ºèƒ½è´Ÿè½½å‡è¡¡ | ç»“åˆæƒé‡å’Œæ•…éšœè½¬ç§» | â­â­â­ |
| `smart_weighted_failover` | æ¸è¿›å¼æ¢å¤ | æ”¯æŒæŒ‰è¯·æ±‚è®¡è´¹ä¼˜åŒ– | â­â­â­ |
| `smart_ai` | æˆæœ¬æ„ŸçŸ¥ä¼˜åŒ– | å°æµé‡å¥åº·æ£€æŸ¥ | â­â­â­â­ |
| `random` | ç®€å•åœºæ™¯ã€æµ‹è¯• | å®ç°ç®€å• | â­ |

### ğŸ§  SmartAIç­–ç•¥è¯¦è§£

SmartAIæ˜¯Berry APIçš„æ ¸å¿ƒåˆ›æ–°ï¼Œä¸“ä¸ºå°æµé‡ã€æˆæœ¬æ•æ„Ÿçš„åœºæ™¯è®¾è®¡ï¼š

**æ ¸å¿ƒç‰¹æ€§ï¼š**
- **æˆæœ¬æ„ŸçŸ¥é€‰æ‹©**ï¼šä¼˜å…ˆé€‰æ‹©ä¾¿å®œçš„åç«¯ï¼Œpremiumåç«¯ä½œä¸ºå¤‡é€‰
- **å°æµé‡ä¼˜åŒ–**ï¼š80%é€‰æ‹©æœ€ä½³åç«¯ï¼Œ20%æ¢ç´¢å…¶ä»–é€‰é¡¹
- **æ™ºèƒ½å¥åº·æ£€æŸ¥**ï¼šåŸºäºç”¨æˆ·è¯·æ±‚è¿›è¡Œè¢«åŠ¨å¥åº·éªŒè¯
- **ä¿¡å¿ƒåº¦æœºåˆ¶**ï¼šåŠ¨æ€è°ƒæ•´åç«¯é€‰æ‹©æƒé‡

**å·¥ä½œåŸç†ï¼š**
```
1. åˆå§‹åŒ–ï¼šæ‰€æœ‰åç«¯è·å¾—åˆå§‹ä¿¡å¿ƒåº¦(0.8)
2. è¯·æ±‚å¤„ç†ï¼šæ ¹æ®ä¿¡å¿ƒåº¦å’Œæƒé‡é€‰æ‹©åç«¯
3. ç»“æœåé¦ˆï¼šæˆåŠŸæå‡ä¿¡å¿ƒåº¦ï¼Œå¤±è´¥é™ä½ä¿¡å¿ƒåº¦
4. åŠ¨æ€è°ƒæ•´ï¼šä¿¡å¿ƒåº¦å½±å“ä¸‹æ¬¡é€‰æ‹©æ¦‚ç‡
5. æ¢ç´¢æœºåˆ¶ï¼š20%æµé‡ç”¨äºæµ‹è¯•å…¶ä»–åç«¯
```

### ğŸ¥ å¥åº·æ£€æŸ¥æœºåˆ¶

Berry API å®ç°äº†å·®å¼‚åŒ–çš„å¥åº·æ£€æŸ¥ç­–ç•¥ï¼š

**æŒ‰è®¡è´¹æ¨¡å¼åˆ†ç±»ï¼š**
- **æŒ‰Tokenè®¡è´¹**ï¼šæ‰§è¡Œä¸»åŠ¨å¥åº·æ£€æŸ¥ï¼ˆè°ƒç”¨æ¨¡å‹APIï¼‰
- **æŒ‰è¯·æ±‚è®¡è´¹**ï¼šä½¿ç”¨è¢«åŠ¨éªŒè¯ï¼ˆåŸºäºç”¨æˆ·è¯·æ±‚ç»“æœï¼‰

**æ£€æŸ¥æµç¨‹ï¼š**
```
å®šæœŸæ£€æŸ¥ â†’ æ¨¡å‹åˆ—è¡¨API â†’ ç®€å•èŠå¤©æµ‹è¯• â†’ æ›´æ–°å¥åº·çŠ¶æ€
     â†“
ç”¨æˆ·è¯·æ±‚ â†’ æˆåŠŸ/å¤±è´¥ â†’ è‡ªåŠ¨æ¢å¤/æ ‡è®°æ•…éšœ
     â†“
æ¸è¿›æ¢å¤ â†’ 30% â†’ 50% â†’ 100% æƒé‡æ¢å¤
```

## âš¡ å¿«é€Ÿå¼€å§‹

### ğŸ“‹ ç¯å¢ƒè¦æ±‚

| ç»„ä»¶ | ç‰ˆæœ¬è¦æ±‚ | æ¨èç‰ˆæœ¬ |
|------|----------|----------|
| **Rust** | 1.70+ | 1.75+ |
| **æ“ä½œç³»ç»Ÿ** | Linux/macOS/Windows | Ubuntu 22.04+ |
| **å†…å­˜** | 512MB+ | 1GB+ |
| **CPU** | 1æ ¸+ | 2æ ¸+ |
| **ç½‘ç»œ** | è®¿é—®AIæœåŠ¡å•†API | ç¨³å®šç½‘ç»œè¿æ¥ |

### ğŸš€ ä¸€é”®éƒ¨ç½²

**æ–¹å¼1ï¼šDockeréƒ¨ç½²ï¼ˆæ¨èï¼‰**
```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/PPKunOfficial/berry-api.git
cd berry-api

# 2. å¤åˆ¶é…ç½®æ–‡ä»¶
cp smart_ai_example.toml config.toml

# 3. ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼Œæ·»åŠ ä½ çš„APIå¯†é’¥
vim config.toml

# 4. å¯åŠ¨æœåŠ¡
docker-compose up -d

# 5. éªŒè¯æœåŠ¡
curl http://localhost:3000/health
```

**æ–¹å¼2ï¼šæºç ç¼–è¯‘**
```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/PPKunOfficial/berry-api.git
cd berry-api

# 2. ç¼–è¯‘é¡¹ç›®ï¼ˆå¯ç”¨å¯è§‚æµ‹æ€§åŠŸèƒ½ï¼‰
cargo build --release --features observability

# 3. é…ç½®æ–‡ä»¶
cp smart_ai_example.toml config.toml
# ç¼–è¾‘config.tomlï¼Œé…ç½®ä½ çš„AIæœåŠ¡æä¾›å•†

# 4. å¯åŠ¨æœåŠ¡
RUST_LOG=info ./target/release/berry-api

# 5. éªŒè¯æœåŠ¡
curl http://localhost:3000/health
```

### âš™ï¸ åŸºç¡€é…ç½®

**é…ç½®æ–‡ä»¶åŠ è½½æœºåˆ¶**

Berry API æ”¯æŒçµæ´»çš„é…ç½®æ–‡ä»¶åŠ è½½ï¼ŒæŒ‰ä»¥ä¸‹ä¼˜å…ˆçº§é¡ºåºï¼š

1. **ç¯å¢ƒå˜é‡** `CONFIG_PATH` æŒ‡å®šçš„è·¯å¾„
2. **é»˜è®¤è·¯å¾„** `config.toml`ï¼ˆå½“å‰ç›®å½•ï¼‰
3. **ç¤ºä¾‹é…ç½®** `config-example.toml`
4. **SmartAIç¤ºä¾‹** `config/smart_ai_example.toml`

**ä½¿ç”¨é…ç½®æ¨¡æ¿**
```bash
# æ–¹å¼1ï¼šå¤åˆ¶å®Œæ•´é…ç½®ç¤ºä¾‹
cp config-example.toml config.toml

# æ–¹å¼2ï¼šå¤åˆ¶SmartAIé…ç½®ç¤ºä¾‹
cp config/smart_ai_example.toml config.toml

# æ–¹å¼3ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡æŒ‡å®šé…ç½®æ–‡ä»¶
export CONFIG_PATH=/path/to/your/config.toml

# ç¼–è¾‘é…ç½®æ–‡ä»¶
vim config.toml
```

**æœ€å°é…ç½®ç¤ºä¾‹**ï¼š
```toml
# å…¨å±€è®¾ç½®
[settings]
health_check_interval_seconds = 30
request_timeout_seconds = 30
max_retries = 3
max_internal_retries = 2

# ç”¨æˆ·è®¤è¯
[users.admin]
name = "Administrator"
token = "berry-admin-token-12345"
allowed_models = []  # ç©ºæ•°ç»„è¡¨ç¤ºå…è®¸è®¿é—®æ‰€æœ‰æ¨¡å‹
enabled = true

# AIæœåŠ¡æä¾›å•†
[providers.openai]
name = "OpenAI"
base_url = "https://api.openai.com/v1"
api_key = "sk-your-openai-key-here"
models = ["gpt-4", "gpt-3.5-turbo"]
enabled = true

# æ¨¡å‹æ˜ å°„
[models.gpt_4]
name = "gpt-4"
strategy = "weighted_failover"  # æ¨èç­–ç•¥
enabled = true

[[models.gpt_4.backends]]
provider = "openai"
model = "gpt-4"
weight = 1.0
priority = 1
enabled = true
```

**é…ç½®æ–‡ä»¶è¯´æ˜**ï¼š
- `config-example.toml` - å®Œæ•´é…ç½®ç¤ºä¾‹ï¼ŒåŒ…å«æ‰€æœ‰é€‰é¡¹å’Œè¯¦ç»†æ³¨é‡Š
- `smart_ai_example.toml` - SmartAIç­–ç•¥ä¸“ç”¨é…ç½®ç¤ºä¾‹
- æ ¹æ®éœ€è¦é€‰æ‹©åˆé€‚çš„æ¨¡æ¿è¿›è¡Œä¿®æ”¹

### ğŸ§ª å¿«é€Ÿæµ‹è¯•

```bash
# 1. æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:3000/health

# 2. è·å–å¯ç”¨æ¨¡å‹
curl -H "Authorization: Bearer berry-admin-token-12345" \
     http://localhost:3000/v1/models

# 3. å‘é€èŠå¤©è¯·æ±‚
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer berry-admin-token-12345" \
  -d '{
    "model": "gpt-4",
    "messages": [{"role": "user", "content": "Hello!"}],
    "stream": false
  }'
```

### ğŸ³ Dockeréƒ¨ç½²

Berry API æä¾›äº†ä¸¤ç§ Docker æ„å»ºæ–¹å¼ï¼Œä»¥æ»¡è¶³ä¸åŒçš„æ€§èƒ½å’Œä½¿ç”¨éœ€æ±‚ï¼š

#### ğŸš€ æ–¹å¼ä¸€ï¼šé¢„ç¼–è¯‘æ„å»ºï¼ˆæ¨èï¼‰

**ç‰¹ç‚¹ï¼š** åœ¨å®¿ä¸»æœºé¢„ç¼–è¯‘ï¼Œé¿å… Docker å†…ç¼–è¯‘çš„æ€§èƒ½æŸå¤±

```bash
# 1. é¢„ç¼–è¯‘äºŒè¿›åˆ¶æ–‡ä»¶
cargo build --bin berry-api --release --target x86_64-unknown-linux-gnu

# 2. å‡†å¤‡ Docker æ„å»ºæ–‡ä»¶
mkdir -p ./docker-binaries
cp target/x86_64-unknown-linux-gnu/release/berry-api ./docker-binaries/

# 3. æ„å»º Docker é•œåƒ
docker build -f Dockerfile.prebuilt -t berry-api:latest .

# 4. è¿è¡Œå®¹å™¨
docker run -p 3000:3000 -v ./config.toml:/app/config.toml:ro berry-api:latest
```

**æˆ–ä½¿ç”¨ä¾¿æ·è„šæœ¬ï¼š**
```bash
# ä¸€é”®é¢„ç¼–è¯‘æ„å»º
./scripts/build-precompiled-docker.sh
```

#### ğŸ”§ æ–¹å¼äºŒï¼šä¼ ç»Ÿå¤šé˜¶æ®µæ„å»º

**ç‰¹ç‚¹ï¼š** å®Œå…¨åœ¨å®¹å™¨å†…ç¼–è¯‘ï¼Œé€‚åˆæœ¬åœ°å¼€å‘

```bash
# ä½¿ç”¨ä¼ ç»Ÿ Dockerfile æ„å»º
docker build -f Dockerfile -t berry-api:latest .
```

#### ğŸ“¦ Docker Compose éƒ¨ç½²

```yaml
# docker-compose.yml
services:
  berry-api:
    image: ppkun00/berry-api:latest  # ä½¿ç”¨é¢„æ„å»ºé•œåƒ
    # æˆ–è€…æœ¬åœ°æ„å»º: build: .
    ports:
      - "3000:3000"
    environment:
      - RUST_LOG=info
      - CONFIG_PATH=/app/config.toml
    volumes:
      - ./config.toml:/app/config.toml:ro
    restart: unless-stopped
```

> ğŸ“– **è¯¦ç»†è¯´æ˜ï¼š** æŸ¥çœ‹ [DOCKER_BUILD.md](DOCKER_BUILD.md) äº†è§£ä¸¤ç§æ„å»ºæ–¹å¼çš„è¯¦ç»†å¯¹æ¯”å’Œä½¿ç”¨æŒ‡å—

```bash
# å¯åŠ¨æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f berry-api

# åœæ­¢æœåŠ¡
docker-compose down
```

## ï¿½ é…ç½®æŒ‡å—

### ğŸ”§ é…ç½®æ–‡ä»¶ç»“æ„

Berry API ä½¿ç”¨TOMLæ ¼å¼çš„é…ç½®æ–‡ä»¶ï¼Œä¸»è¦åŒ…å«4ä¸ªéƒ¨åˆ†ï¼š

```toml
[settings]        # å…¨å±€è®¾ç½®
[users.*]         # ç”¨æˆ·è®¤è¯é…ç½®
[providers.*]     # AIæœåŠ¡æä¾›å•†é…ç½®
[models.*]        # æ¨¡å‹æ˜ å°„é…ç½®
```

### âš™ï¸ å…¨å±€è®¾ç½® (settings)

```toml
[settings]
# åŸºç¡€è®¾ç½®
health_check_interval_seconds = 30    # å¥åº·æ£€æŸ¥é—´éš”
request_timeout_seconds = 30          # è¯·æ±‚è¶…æ—¶æ—¶é—´
max_retries = 3                       # æœ€å¤§é‡è¯•æ¬¡æ•°
max_internal_retries = 2              # å†…éƒ¨é‡è¯•æ¬¡æ•°
health_check_timeout_seconds = 10     # å¥åº·æ£€æŸ¥è¶…æ—¶

# ç†”æ–­å™¨è®¾ç½®
circuit_breaker_failure_threshold = 5 # ç†”æ–­å™¨å¤±è´¥é˜ˆå€¼
circuit_breaker_timeout_seconds = 60  # ç†”æ–­å™¨è¶…æ—¶æ—¶é—´
recovery_check_interval_seconds = 120 # æ¢å¤æ£€æŸ¥é—´éš”

# SmartAI è®¾ç½®ï¼ˆå¯é€‰ï¼‰
[settings.smart_ai]
initial_confidence = 0.8              # åˆå§‹ä¿¡å¿ƒåº¦
min_confidence = 0.05                 # æœ€å°ä¿¡å¿ƒåº¦
enable_time_decay = true              # å¯ç”¨æ—¶é—´è¡°å‡
exploration_ratio = 0.2               # æ¢ç´¢æµé‡æ¯”ä¾‹
```

### ğŸ‘¤ ç”¨æˆ·è®¤è¯é…ç½® (users)

```toml
# ç®¡ç†å‘˜ç”¨æˆ·
[users.admin]
name = "Administrator"
token = "berry-admin-token-12345"
allowed_models = []                   # ç©ºæ•°ç»„ = è®¿é—®æ‰€æœ‰æ¨¡å‹
enabled = true
tags = ["admin", "unlimited"]

# æ™®é€šç”¨æˆ·
[users.user1]
name = "Regular User"
token = "berry-user1-token-67890"
allowed_models = ["gpt-3.5-turbo"]   # é™åˆ¶è®¿é—®æ¨¡å‹
enabled = true
tags = ["user", "basic"]
# é€Ÿç‡é™åˆ¶ï¼ˆå¯é€‰ï¼‰
[users.user1.rate_limit]
requests_per_minute = 60
requests_per_hour = 1000

# é«˜çº§ç”¨æˆ·
[users.premium]
name = "Premium User"
token = "berry-premium-token-abcde"
allowed_models = ["gpt-4", "claude-3"]
enabled = true
tags = ["premium", "advanced"]
```

### ğŸ”Œ Provideré…ç½® (providers)

```toml
# OpenAI é…ç½®
[providers.openai]
name = "OpenAI"
base_url = "https://api.openai.com/v1"
api_key = "sk-your-openai-key-here"
models = ["gpt-4", "gpt-3.5-turbo"]
enabled = true
timeout_seconds = 30
backend_type = "openai"               # åç«¯ç±»å‹

# Azure OpenAI é…ç½®
[providers.azure]
name = "Azure OpenAI"
base_url = "https://your-resource.openai.azure.com"
api_key = "your-azure-key-here"
models = ["gpt-4", "gpt-35-turbo"]
enabled = true
backend_type = "openai"
# è‡ªå®šä¹‰è¯·æ±‚å¤´
[providers.azure.headers]
"api-version" = "2024-02-01"

# Anthropic Claude é…ç½®
[providers.anthropic]
name = "Anthropic"
base_url = "https://api.anthropic.com"
api_key = "sk-ant-your-key-here"
models = ["claude-3-opus", "claude-3-sonnet"]
enabled = true
backend_type = "claude"               # Claudeæ ¼å¼
```

### ğŸ¯ æ¨¡å‹æ˜ å°„é…ç½® (models)

```toml
# åŸºç¡€æ¨¡å‹é…ç½®
[models.gpt_4]
name = "gpt-4"                        # å¯¹å¤–æš´éœ²çš„æ¨¡å‹å
strategy = "weighted_failover"        # è´Ÿè½½å‡è¡¡ç­–ç•¥
enabled = true

# åç«¯é…ç½® - ä¸»è¦æœåŠ¡
[[models.gpt_4.backends]]
provider = "openai"
model = "gpt-4"
weight = 0.7                          # 70% æƒé‡
priority = 1                          # æœ€é«˜ä¼˜å…ˆçº§
enabled = true
billing_mode = "per_token"            # è®¡è´¹æ¨¡å¼
tags = ["premium"]

# åç«¯é…ç½® - å¤‡ç”¨æœåŠ¡
[[models.gpt_4.backends]]
provider = "azure"
model = "gpt-4"
weight = 0.3                          # 30% æƒé‡
priority = 2                          # å¤‡ç”¨ä¼˜å…ˆçº§
enabled = true
billing_mode = "per_token"
tags = ["enterprise"]
```

### ğŸ“‹ é…ç½®æ–‡ä»¶æ¨¡æ¿

Berry API æä¾›äº†å¤šä¸ªé…ç½®æ–‡ä»¶æ¨¡æ¿ï¼š

**1. å®Œæ•´é…ç½®ç¤ºä¾‹ (`config-example.toml`)**
- âœ… åŒ…å«æ‰€æœ‰é…ç½®é€‰é¡¹å’Œè¯¦ç»†æ³¨é‡Š
- âœ… 8ç§è´Ÿè½½å‡è¡¡ç­–ç•¥ç¤ºä¾‹
- âœ… å¤šç§ç”¨æˆ·æƒé™é…ç½®
- âœ… å®Œæ•´çš„Provideré…ç½®ç¤ºä¾‹
- âœ… å®‰å…¨å’Œæ€§èƒ½ä¼˜åŒ–å»ºè®®

**2. SmartAIä¸“ç”¨é…ç½® (`smart_ai_example.toml`)**
- âœ… SmartAIç­–ç•¥ä¸“ç”¨é…ç½®
- âœ… æˆæœ¬æ„ŸçŸ¥è´Ÿè½½å‡è¡¡
- âœ… å°æµé‡å¥åº·æ£€æŸ¥ä¼˜åŒ–
- âœ… ä¿¡å¿ƒåº¦è°ƒæ•´å‚æ•°

**ä½¿ç”¨æ–¹æ³•**ï¼š
```bash
# ä½¿ç”¨å®Œæ•´é…ç½®æ¨¡æ¿
cp config-example.toml config.toml

# ä½¿ç”¨SmartAIé…ç½®æ¨¡æ¿
cp smart_ai_example.toml config.toml

# ç¼–è¾‘é…ç½®æ–‡ä»¶
vim config.toml
```

## ğŸ”Œ APIä½¿ç”¨æŒ‡å—

Berry API å®Œå…¨å…¼å®¹ OpenAI API æ ¼å¼ï¼Œå¯ä»¥æ— ç¼æ›¿æ¢ç°æœ‰çš„ OpenAI å®¢æˆ·ç«¯ã€‚

### ğŸ” è®¤è¯ä¸æƒé™ç®¡ç†

**è®¤è¯æ–¹å¼**
```bash
Authorization: Bearer your-token-here
```

**æƒé™æ§åˆ¶**
- **ç®¡ç†å‘˜ç”¨æˆ·**ï¼š`allowed_models = []` å¯è®¿é—®æ‰€æœ‰æ¨¡å‹
- **æ™®é€šç”¨æˆ·**ï¼š`allowed_models = ["gpt-4"]` åªèƒ½è®¿é—®æŒ‡å®šæ¨¡å‹
- **ç”¨æˆ·æ ‡ç­¾**ï¼šæ”¯æŒåŸºäºæ ‡ç­¾çš„åç«¯è¿‡æ»¤

### ğŸ’¬ èŠå¤©å®Œæˆæ¥å£

**éæµå¼è¯·æ±‚**
```bash
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer berry-admin-token-12345" \
  -d '{
    "model": "gpt-4",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "Hello, world!"}
    ],
    "stream": false,
    "max_tokens": 1000,
    "temperature": 0.7,
    "top_p": 1.0,
    "frequency_penalty": 0,
    "presence_penalty": 0
  }'
```

**æµå¼è¯·æ±‚**
```bash
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer berry-admin-token-12345" \
  -d '{
    "model": "gpt-4",
    "messages": [
      {"role": "user", "content": "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—"}
    ],
    "stream": true,
    "max_tokens": 1000
  }'
```

**Python SDK ç¤ºä¾‹**
```python
import openai

# é…ç½®å®¢æˆ·ç«¯
client = openai.OpenAI(
    api_key="berry-admin-token-12345",
    base_url="http://localhost:3000/v1"
)

# éæµå¼è¯·æ±‚
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello, world!"}
    ],
    stream=False
)
print(response.choices[0].message.content)

# æµå¼è¯·æ±‚
stream = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Tell me a story"}],
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```

**Node.js ç¤ºä¾‹**
```javascript
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: 'berry-admin-token-12345',
  baseURL: 'http://localhost:3000/v1',
});

async function main() {
  const completion = await openai.chat.completions.create({
    messages: [{ role: 'user', content: 'Hello world' }],
    model: 'gpt-4',
  });

  console.log(completion.choices[0].message.content);
}

main();
```

### ğŸ“‹ æ¨¡å‹ç®¡ç†

**è·å–å¯ç”¨æ¨¡å‹**
```bash
curl http://localhost:3000/v1/models \
  -H "Authorization: Bearer berry-admin-token-12345"
```

**å“åº”ç¤ºä¾‹**
```json
{
  "object": "list",
  "data": [
    {
      "id": "gpt-4",
      "object": "model",
      "created": 1677610602,
      "owned_by": "berry-api"
    },
    {
      "id": "gpt-3.5-turbo",
      "object": "model",
      "created": 1677610602,
      "owned_by": "berry-api"
    }
  ]
}
```

### ğŸ¥ å¥åº·æ£€æŸ¥ä¸ç›‘æ§

**åŸºç¡€å¥åº·æ£€æŸ¥**
```bash
curl http://localhost:3000/health
```

**è¯¦ç»†å¥åº·çŠ¶æ€**
```bash
curl http://localhost:3000/metrics
```

**Prometheus æŒ‡æ ‡**
```bash
curl http://localhost:3000/prometheus
```

### ğŸ›ï¸ ç®¡ç†æ¥å£

**è·å–æ¨¡å‹æƒé‡**
```bash
curl http://localhost:3000/admin/model-weights \
  -H "Authorization: Bearer admin-token"
```

**è·å–åç«¯å¥åº·çŠ¶æ€**
```bash
curl http://localhost:3000/admin/backend-health \
  -H "Authorization: Bearer admin-token"
```

**SmartAI æƒé‡æŸ¥çœ‹**
```bash
curl http://localhost:3000/smart-ai/weights
curl http://localhost:3000/smart-ai/models/gpt-4/weights
```

## ğŸ“Š å®Œæ•´APIç«¯ç‚¹

| ç«¯ç‚¹ | æ–¹æ³• | è®¤è¯ | æè¿° |
|------|------|------|------|
| `/` | GET | âŒ | æœåŠ¡é¦–é¡µ |
| `/health` | GET | âŒ | åŸºç¡€å¥åº·æ£€æŸ¥ |
| `/metrics` | GET | âŒ | è¯¦ç»†æ€§èƒ½æŒ‡æ ‡ |
| `/prometheus` | GET | âŒ | Prometheusæ ¼å¼æŒ‡æ ‡ |
| `/models` | GET | âœ… | å¯ç”¨æ¨¡å‹åˆ—è¡¨ |
| `/v1/chat/completions` | POST | âœ… | èŠå¤©å®Œæˆï¼ˆOpenAIå…¼å®¹ï¼‰ |
| `/v1/models` | GET | âœ… | æ¨¡å‹åˆ—è¡¨ï¼ˆOpenAIå…¼å®¹ï¼‰ |
| `/v1/health` | GET | âŒ | OpenAIå…¼å®¹å¥åº·æ£€æŸ¥ |
| `/admin/model-weights` | GET | âœ… | æ¨¡å‹æƒé‡ä¿¡æ¯ |
| `/admin/backend-health` | GET | âœ… | åç«¯å¥åº·çŠ¶æ€ |
| `/admin/system-stats` | GET | âœ… | ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯ |
| `/smart-ai/weights` | GET | âŒ | SmartAIå…¨å±€æƒé‡ |
| `/smart-ai/models/{model}/weights` | GET | âŒ | ç‰¹å®šæ¨¡å‹SmartAIæƒé‡ |

## ğŸ”§ è´Ÿè½½å‡è¡¡ç­–ç•¥è¯¦è§£

### ç­–ç•¥é€‰æ‹©æŒ‡å—

| ç­–ç•¥ | é€‚ç”¨åœºæ™¯ | ä¼˜åŠ¿ | åŠ£åŠ¿ |
|------|----------|------|------|
| `weighted_random` | æˆæœ¬æ§åˆ¶ã€æŒ‰æ€§èƒ½åˆ†é… | çµæ´»çš„æƒé‡åˆ†é… | å¯èƒ½ä¸å¤Ÿå‡åŒ€ |
| `round_robin` | ç®€å•å‡è¡¡ã€ç›¸åŒæ€§èƒ½åç«¯ | å®Œå…¨å‡åŒ€åˆ†é… | ä¸è€ƒè™‘åç«¯æ€§èƒ½å·®å¼‚ |
| `least_latency` | æ€§èƒ½ä¼˜åŒ–ã€å»¶è¿Ÿæ•æ„Ÿ | è‡ªåŠ¨é€‰æ‹©æœ€å¿«åç«¯ | éœ€è¦å»¶è¿Ÿç»Ÿè®¡ |
| `failover` | é«˜å¯ç”¨ã€ä¸»å¤‡åœºæ™¯ | æ˜ç¡®çš„ä¼˜å…ˆçº§ | ä¸»åç«¯å‹åŠ›å¤§ |
| `random` | ç®€å•åœºæ™¯ã€æµ‹è¯• | å®ç°ç®€å• | æ— ä¼˜åŒ–ç­–ç•¥ |
| `weighted_failover` | æ™ºèƒ½è´Ÿè½½å‡è¡¡ | ç»“åˆæƒé‡å’Œæ•…éšœè½¬ç§» | é…ç½®ç›¸å¯¹å¤æ‚ |

### 1. åŠ æƒéšæœº (weighted_random)
æ ¹æ®æƒé‡éšæœºé€‰æ‹©åç«¯ï¼Œé€‚åˆæŒ‰æˆæœ¬æˆ–æ€§èƒ½åˆ†é…æµé‡ï¼š
```toml
[models.cost_optimized]
name = "cost-optimized"
strategy = "weighted_random"
enabled = true

[[models.cost_optimized.backends]]
provider = "cheap-provider"
model = "gpt-3.5-turbo"
weight = 0.7  # 70% æµé‡ç»™ä¾¿å®œçš„æœåŠ¡
priority = 1
enabled = true

[[models.cost_optimized.backends]]
provider = "premium-provider"
model = "gpt-3.5-turbo"
weight = 0.3  # 30% æµé‡ç»™é«˜è´¨é‡æœåŠ¡
priority = 2
enabled = true
```

### 2. è½®è¯¢ (round_robin)
ä¾æ¬¡è½®è¯¢æ‰€æœ‰å¯ç”¨åç«¯ï¼Œé€‚åˆæ€§èƒ½ç›¸è¿‘çš„åç«¯ï¼š
```toml
[models.balanced]
name = "balanced"
strategy = "round_robin"
enabled = true

[[models.balanced.backends]]
provider = "provider-a"
model = "gpt-4"
weight = 1.0  # è½®è¯¢ä¸­æƒé‡æ— æ•ˆ
priority = 1
enabled = true

[[models.balanced.backends]]
provider = "provider-b"
model = "gpt-4"
weight = 1.0
priority = 2
enabled = true
```

### 3. æœ€ä½å»¶è¿Ÿ (least_latency)
è‡ªåŠ¨é€‰æ‹©å“åº”æ—¶é—´æœ€çŸ­çš„åç«¯ï¼š
```toml
[models.fast_response]
name = "fast-response"
strategy = "least_latency"
enabled = true

[[models.fast_response.backends]]
provider = "fast-provider"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 1
enabled = true

[[models.fast_response.backends]]
provider = "slow-provider"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 2
enabled = true
```

### 4. æ•…éšœè½¬ç§» (failover)
æŒ‰ä¼˜å…ˆçº§é¡ºåºé€‰æ‹©ï¼Œä¸»è¦ç”¨äºä¸»å¤‡åœºæ™¯ï¼š
```toml
[models.high_availability]
name = "high-availability"
strategy = "failover"
enabled = true

[[models.high_availability.backends]]
provider = "primary-provider"
model = "gpt-4"
weight = 1.0
priority = 1  # æœ€é«˜ä¼˜å…ˆçº§ï¼Œä¼˜å…ˆä½¿ç”¨
enabled = true

[[models.high_availability.backends]]
provider = "backup-provider"
model = "gpt-4"
weight = 1.0
priority = 2  # å¤‡ç”¨ï¼Œä¸»æœåŠ¡æ•…éšœæ—¶ä½¿ç”¨
enabled = true

[[models.high_availability.backends]]
provider = "emergency-provider"
model = "gpt-4"
weight = 1.0
priority = 3  # åº”æ€¥ï¼Œå‰ä¸¤ä¸ªéƒ½æ•…éšœæ—¶ä½¿ç”¨
enabled = true
```

### 5. æƒé‡æ•…éšœè½¬ç§» (weighted_failover) ğŸ†•
ç»“åˆæƒé‡é€‰æ‹©å’Œæ•…éšœè½¬ç§»çš„æ™ºèƒ½ç­–ç•¥ï¼š

**å·¥ä½œåŸç†**ï¼š
1. **æ­£å¸¸æƒ…å†µ**: ä»æ‰€æœ‰å¥åº·çš„åç«¯ä¸­æŒ‰æƒé‡éšæœºé€‰æ‹©
2. **æ•…éšœæƒ…å†µ**: è‡ªåŠ¨å±è”½ä¸å¥åº·çš„åç«¯ï¼Œåªåœ¨å¥åº·çš„åç«¯ä¸­é€‰æ‹©
3. **å…¨éƒ¨æ•…éšœ**: å¦‚æœæ‰€æœ‰åç«¯éƒ½ä¸å¥åº·ï¼Œä»æŒ‰æƒé‡é€‰æ‹©ï¼ˆè€Œéä¼˜å…ˆçº§ï¼‰
4. **è‡ªåŠ¨æ¢å¤**: åç«¯æ¢å¤å¥åº·åè‡ªåŠ¨é‡æ–°åŠ å…¥è´Ÿè½½å‡è¡¡

```toml
[models.smart_model]
name = "smart-model"
strategy = "weighted_failover"
enabled = true

[[models.smart_model.backends]]
provider = "openai-main"
model = "gpt-4"
weight = 0.6    # 60%æƒé‡ - ä¸»è¦æœåŠ¡
priority = 1    # æœ€é«˜ä¼˜å…ˆçº§
enabled = true

[[models.smart_model.backends]]
provider = "openai-backup"
model = "gpt-4"
weight = 0.3    # 30%æƒé‡ - å¤‡ç”¨æœåŠ¡
priority = 2    # ä¸­ç­‰ä¼˜å…ˆçº§
enabled = true

[[models.smart_model.backends]]
provider = "azure"
model = "gpt-4"
weight = 0.1    # 10%æƒé‡ - åº”æ€¥æœåŠ¡
priority = 3    # æœ€ä½ä¼˜å…ˆçº§
enabled = true
```

### 6. éšæœº (random)
å®Œå…¨éšæœºé€‰æ‹©ï¼Œé€‚åˆç®€å•åœºæ™¯ï¼š
```toml
[models.simple_random]
name = "simple-random"
strategy = "random"
enabled = true

[[models.simple_random.backends]]
provider = "provider-a"
model = "gpt-3.5-turbo"
weight = 1.0  # éšæœºç­–ç•¥ä¸­æƒé‡æ— æ•ˆ
priority = 1
enabled = true
```

## ğŸ¥ å¥åº·æ£€æŸ¥ä¸æ•…éšœå¤„ç†

### å¥åº·æ£€æŸ¥é…ç½®
```toml
[settings]
health_check_interval_seconds = 30    # æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
circuit_breaker_failure_threshold = 5 # ç†”æ–­é˜ˆå€¼
circuit_breaker_timeout_seconds = 60  # ç†”æ–­æ¢å¤æ—¶é—´ï¼ˆç§’ï¼‰
```

### å¥åº·æ£€æŸ¥æœºåˆ¶
1. **å®šæœŸæ£€æŸ¥**: æ¯30ç§’è‡ªåŠ¨æ£€æŸ¥æ‰€æœ‰Providerçš„å¥åº·çŠ¶æ€
2. **æ¨¡å‹åˆ—è¡¨éªŒè¯**: é€šè¿‡è°ƒç”¨ `/v1/models` ç«¯ç‚¹éªŒè¯æœåŠ¡å¯ç”¨æ€§
3. **èŠå¤©è¯·æ±‚æµ‹è¯•**: å‘é€ç®€å•çš„èŠå¤©è¯·æ±‚éªŒè¯æ¨¡å‹åŠŸèƒ½
4. **è‡ªåŠ¨æ ‡è®°**: æ ¹æ®æ£€æŸ¥ç»“æœè‡ªåŠ¨æ ‡è®°Providerä¸ºå¥åº·/ä¸å¥åº·

### æ•…éšœè½¬ç§»æµç¨‹
å½“æŸä¸ªProviderå‡ºç°æ•…éšœæ—¶ï¼š

1. **æ•…éšœæ£€æµ‹**
   - APIè¯·æ±‚å¤±è´¥
   - å¥åº·æ£€æŸ¥å¤±è´¥
   - å“åº”è¶…æ—¶

2. **è‡ªåŠ¨å¤„ç†**
   - ç«‹å³æ ‡è®°ä¸ºä¸å¥åº·
   - å°†æµé‡åˆ‡æ¢åˆ°å…¶ä»–å¥åº·çš„Provider
   - è®°å½•æ•…éšœæŒ‡æ ‡

3. **æ¢å¤æ£€æµ‹**
   - å®šæœŸé‡è¯•æ•…éšœçš„Provider
   - å¥åº·æ£€æŸ¥é€šè¿‡åè‡ªåŠ¨æ¢å¤
   - ç”¨æˆ·è¯·æ±‚æˆåŠŸä¹Ÿä¼šè§¦å‘æ¢å¤

4. **æµé‡æ¢å¤**
   - æ¢å¤åè‡ªåŠ¨é‡æ–°åŠ å…¥è´Ÿè½½å‡è¡¡
   - æŒ‰é…ç½®çš„æƒé‡åˆ†é…æµé‡

### ç†”æ–­æœºåˆ¶
```
æ­£å¸¸çŠ¶æ€ â”€â”€å¤±è´¥æ¬¡æ•°è¾¾åˆ°é˜ˆå€¼â”€â”€â–¶ ç†”æ–­çŠ¶æ€
    â–²                           â”‚
    â”‚                           â”‚
    â””â”€â”€è¶…æ—¶åè‡ªåŠ¨å°è¯•æ¢å¤â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **è§¦å‘æ¡ä»¶**: è¿ç»­å¤±è´¥æ¬¡æ•°è¾¾åˆ° `circuit_breaker_failure_threshold`
- **ç†”æ–­æœŸé—´**: ä¸ä¼šå‘è¯¥Providerå‘é€è¯·æ±‚
- **è‡ªåŠ¨æ¢å¤**: è¶…è¿‡ `circuit_breaker_timeout_seconds` åè‡ªåŠ¨å°è¯•æ¢å¤

### æ•…éšœå¤„ç†æœ€ä½³å®è·µ

1. **å¤šProvideré…ç½®**: ä¸ºæ¯ä¸ªæ¨¡å‹é…ç½®å¤šä¸ªProvider
2. **åˆç†çš„æƒé‡åˆ†é…**: ä¸»Provideræƒé‡é«˜ï¼Œå¤‡ç”¨Provideræƒé‡ä½
3. **é€‚å½“çš„è¶…æ—¶è®¾ç½®**: é¿å…è¿‡é•¿çš„ç­‰å¾…æ—¶é—´
4. **ç›‘æ§å‘Šè­¦**: å®šæœŸæ£€æŸ¥å¥åº·çŠ¶æ€å’ŒæŒ‡æ ‡

## ğŸ§ª æµ‹è¯•ä¸è°ƒè¯•

### 1. å•å…ƒæµ‹è¯•
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
cargo test

# è¿è¡Œç‰¹å®šæ¨¡å—æµ‹è¯•
cargo test loadbalance
cargo test config
cargo test auth

# è¿è¡Œé›†æˆæµ‹è¯•
cargo test --test integration

# æ˜¾ç¤ºæµ‹è¯•è¾“å‡º
cargo test -- --nocapture
```

### 2. åŠŸèƒ½æµ‹è¯•
```bash
# æµ‹è¯•åŸºæœ¬åŠŸèƒ½
./test_auth.sh

# è°ƒè¯•æ¼”ç¤º
./debug_demo.sh

# å¥åº·æ£€æŸ¥æ¼”ç¤º
cargo run --example initial_health_check_demo
```

### 3. è°ƒè¯•æ—¥å¿—
å¯ç”¨è¯¦ç»†æ—¥å¿—è¿›è¡Œè°ƒè¯•ï¼š
```bash
# å¯ç”¨è°ƒè¯•æ—¥å¿—
RUST_LOG=debug cargo run

# åªæ˜¾ç¤ºç‰¹å®šæ¨¡å—çš„æ—¥å¿—
RUST_LOG=berry_api_api=debug cargo run

# æ˜¾ç¤ºæ‰€æœ‰æ—¥å¿—çº§åˆ«
RUST_LOG=trace cargo run
```

### 4. é…ç½®éªŒè¯
```bash
# éªŒè¯é…ç½®æ–‡ä»¶è¯­æ³•
cargo run -- --check-config

# ä½¿ç”¨æµ‹è¯•é…ç½®
CONFIG_PATH="test_config.toml" cargo run
```

### 5. æ€§èƒ½æµ‹è¯•
```bash
# ä½¿ç”¨ wrk è¿›è¡Œå‹åŠ›æµ‹è¯•
wrk -t12 -c400 -d30s --script=test.lua http://localhost:3000/v1/chat/completions

# ä½¿ç”¨ curl æµ‹è¯•å»¶è¿Ÿ
time curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer berry-admin-token-12345" \
  -d '{"model": "gpt-4", "messages": [{"role": "user", "content": "Hello"}]}'
```

## ğŸ› ï¸ å‘½ä»¤è¡Œå·¥å…· (berry-cli)

Berry CLI æä¾›äº†ä¸°å¯Œçš„è¿ç»´ç®¡ç†åŠŸèƒ½ï¼š

### ğŸ“‹ é…ç½®ç®¡ç†

**éªŒè¯é…ç½®æ–‡ä»¶**
```bash
# éªŒè¯é»˜è®¤é…ç½®
berry-cli validate-config

# éªŒè¯æŒ‡å®šé…ç½®æ–‡ä»¶
berry-cli validate-config -c /path/to/config.toml

# è¾“å‡ºç¤ºä¾‹
âœ… Configuration is valid
  - 2 providers configured
  - 3 models configured
  - 5 users configured
```

**ç”Ÿæˆé…ç½®æ–‡ä»¶**
```bash
# ç”ŸæˆåŸºç¡€é…ç½®
berry-cli generate-config -o config_example.toml

# ç”Ÿæˆé«˜çº§é…ç½®ï¼ˆåŒ…å«æ‰€æœ‰åŠŸèƒ½ï¼‰
berry-cli generate-config -o advanced_config.toml --advanced
```

### ğŸ¥ å¥åº·æ£€æŸ¥

**æ£€æŸ¥æ‰€æœ‰åç«¯**
```bash
berry-cli health-check -c config.toml
# è¾“å‡ºï¼šâœ… Health check completed
```

**æ£€æŸ¥ç‰¹å®šProvider**
```bash
berry-cli health-check -c config.toml -p openai
# è¾“å‡ºï¼šâœ… Provider openai is healthy
```

### ğŸ“Š æŒ‡æ ‡æŸ¥çœ‹

**æŸ¥çœ‹æœåŠ¡æŒ‡æ ‡**
```bash
# åŸºç¡€æŒ‡æ ‡
berry-cli metrics -c config.toml

# è¯¦ç»†æŒ‡æ ‡
berry-cli metrics -c config.toml --detailed
```

### ğŸ§ª åç«¯æµ‹è¯•

**æµ‹è¯•åç«¯è¿æ¥**
```bash
berry-cli test-backend -c config.toml -p openai -m gpt-4
# è¾“å‡ºï¼šâœ… Backend openai:gpt-4 connectivity test passed
```

### ğŸ”§ CLI å®‰è£…

```bash
# ç¼–è¯‘CLIå·¥å…·
cargo build --release -p berry-cli

# å®‰è£…åˆ°ç³»ç»Ÿè·¯å¾„
sudo cp target/release/berry-cli /usr/local/bin/

# éªŒè¯å®‰è£…
berry-cli --help
```

## ï¿½ï¸ å‘½ä»¤è¡Œå·¥å…· (berry-cli)

Berry CLI æä¾›äº†ä¸°å¯Œçš„è¿ç»´ç®¡ç†åŠŸèƒ½ï¼š

### ğŸ“‹ é…ç½®ç®¡ç†

**éªŒè¯é…ç½®æ–‡ä»¶**
```bash
# éªŒè¯é»˜è®¤é…ç½®
berry-cli validate-config

# éªŒè¯æŒ‡å®šé…ç½®æ–‡ä»¶
berry-cli validate-config -c /path/to/config.toml

# è¾“å‡ºç¤ºä¾‹
âœ… Configuration is valid
  - 2 providers configured
  - 3 models configured
  - 5 users configured
```

**ç”Ÿæˆé…ç½®æ–‡ä»¶**
```bash
# ç”ŸæˆåŸºç¡€é…ç½®
berry-cli generate-config -o config_example.toml

# ç”Ÿæˆé«˜çº§é…ç½®ï¼ˆåŒ…å«æ‰€æœ‰åŠŸèƒ½ï¼‰
berry-cli generate-config -o advanced_config.toml --advanced
```

### ğŸ¥ å¥åº·æ£€æŸ¥

**æ£€æŸ¥æ‰€æœ‰åç«¯**
```bash
berry-cli health-check -c config.toml
# è¾“å‡ºï¼šâœ… Health check completed
```

**æ£€æŸ¥ç‰¹å®šProvider**
```bash
berry-cli health-check -c config.toml -p openai
# è¾“å‡ºï¼šâœ… Provider openai is healthy
```

### ğŸ“Š æŒ‡æ ‡æŸ¥çœ‹

**æŸ¥çœ‹æœåŠ¡æŒ‡æ ‡**
```bash
# åŸºç¡€æŒ‡æ ‡
berry-cli metrics -c config.toml

# è¯¦ç»†æŒ‡æ ‡
berry-cli metrics -c config.toml --detailed
```

### ğŸ§ª åç«¯æµ‹è¯•

**æµ‹è¯•åç«¯è¿æ¥**
```bash
berry-cli test-backend -c config.toml -p openai -m gpt-4
# è¾“å‡ºï¼šâœ… Backend openai:gpt-4 connectivity test passed
```

### ğŸ”§ CLI å®‰è£…

```bash
# ç¼–è¯‘CLIå·¥å…·
cargo build --release -p berry-cli

# å®‰è£…åˆ°ç³»ç»Ÿè·¯å¾„
sudo cp target/release/berry-cli /usr/local/bin/

# éªŒè¯å®‰è£…
berry-cli --help
```

## ï¿½ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–ä¸éƒ¨ç½²

### æ€§èƒ½è°ƒä¼˜å»ºè®®

1. **è¿æ¥æ± ä¼˜åŒ–**
   ```toml
   [settings]
   request_timeout_seconds = 30      # æ ¹æ®ç½‘ç»œæƒ…å†µè°ƒæ•´
   max_retries = 3                   # é¿å…è¿‡å¤šé‡è¯•
   health_check_interval_seconds = 30 # å¹³è¡¡æ£€æŸ¥é¢‘ç‡å’Œæ€§èƒ½
   ```

2. **æƒé‡åˆ†é…ç­–ç•¥**
   - æ ¹æ®Providerçš„å®é™…æ€§èƒ½å’Œæˆæœ¬è°ƒæ•´æƒé‡
   - é«˜æ€§èƒ½Provideråˆ†é…æ›´é«˜æƒé‡
   - å¤‡ç”¨Providerä¿æŒè¾ƒä½æƒé‡

3. **è¶…æ—¶è®¾ç½®**
   - è®¾ç½®åˆç†çš„è¯·æ±‚è¶…æ—¶æ—¶é—´
   - é¿å…è¿‡é•¿çš„ç­‰å¾…å¯¼è‡´ç”¨æˆ·ä½“éªŒå·®
   - è€ƒè™‘ä¸åŒProviderçš„å“åº”ç‰¹æ€§

4. **ç†”æ–­å‚æ•°**
   ```toml
   circuit_breaker_failure_threshold = 5  # æ ¹æ®å®¹é”™éœ€æ±‚è°ƒæ•´
   circuit_breaker_timeout_seconds = 60   # å¹³è¡¡æ¢å¤é€Ÿåº¦å’Œç¨³å®šæ€§
   ```

## ğŸ“Š ç›‘æ§ä¸å¯è§‚æµ‹æ€§

Berry API æä¾›å®Œæ•´çš„å¯è§‚æµ‹æ€§æ”¯æŒï¼ŒåŒ…æ‹¬æŒ‡æ ‡æ”¶é›†ã€æ—¥å¿—è®°å½•å’Œå¥åº·ç›‘æ§ã€‚

### ğŸ¯ æ ¸å¿ƒæŒ‡æ ‡

**HTTP è¯·æ±‚æŒ‡æ ‡**
- `http_requests_total` - æ€»è¯·æ±‚æ•°ï¼ˆæŒ‰çŠ¶æ€ç ã€æ–¹æ³•ã€è·¯å¾„åˆ†ç±»ï¼‰
- `http_request_duration_seconds` - è¯·æ±‚å»¶è¿Ÿåˆ†å¸ƒ
- `http_requests_in_flight` - å½“å‰å¤„ç†ä¸­çš„è¯·æ±‚æ•°

**åç«¯å¥åº·æŒ‡æ ‡**
- `backend_health_status` - åç«¯å¥åº·çŠ¶æ€ï¼ˆ0=ä¸å¥åº·ï¼Œ1=å¥åº·ï¼‰
- `backend_request_count_total` - åç«¯è¯·æ±‚æ€»æ•°
- `backend_error_count_total` - åç«¯é”™è¯¯æ€»æ•°
- `backend_latency_seconds` - åç«¯å“åº”å»¶è¿Ÿ

**è´Ÿè½½å‡è¡¡æŒ‡æ ‡**
- `load_balance_selections_total` - è´Ÿè½½å‡è¡¡é€‰æ‹©æ¬¡æ•°
- `smart_ai_confidence_score` - SmartAIä¿¡å¿ƒåº¦åˆ†æ•°
- `circuit_breaker_state` - ç†”æ–­å™¨çŠ¶æ€

### ğŸ“ˆ Prometheus é›†æˆ

**å¯ç”¨å¯è§‚æµ‹æ€§åŠŸèƒ½**
```bash
# ç¼–è¯‘æ—¶å¯ç”¨observabilityç‰¹æ€§
cargo build --release --features observability

# æˆ–åœ¨Cargo.tomlä¸­é…ç½®
[features]
default = ["observability"]
observability = ["prometheus", "axum-prometheus"]
```

**Prometheus é…ç½®**
```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'berry-api'
    static_configs:
      - targets: ['localhost:3000']
    metrics_path: '/prometheus'
    scrape_interval: 10s
```

**Grafana ä»ªè¡¨æ¿**

åˆ›å»º Grafana ä»ªè¡¨æ¿ç›‘æ§å…³é”®æŒ‡æ ‡ï¼š

```json
{
  "dashboard": {
    "title": "Berry API Dashboard",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{status}}"
          }
        ]
      },
      {
        "title": "Backend Health",
        "type": "stat",
        "targets": [
          {
            "expr": "backend_health_status",
            "legendFormat": "{{provider}}:{{model}}"
          }
        ]
      }
    ]
  }
}
```

### ğŸ“ æ—¥å¿—ç®¡ç†

**æ—¥å¿—çº§åˆ«é…ç½®**
```bash
# ç¯å¢ƒå˜é‡é…ç½®
export RUST_LOG=info                    # åŸºç¡€æ—¥å¿—
export RUST_LOG=debug                   # è°ƒè¯•æ—¥å¿—
export RUST_LOG=berry_api=debug         # ç‰¹å®šæ¨¡å—æ—¥å¿—
export RUST_LOG=trace                   # è¯¦ç»†è·Ÿè¸ªæ—¥å¿—
```

**ç»“æ„åŒ–æ—¥å¿—ç¤ºä¾‹**
```json
{
  "timestamp": "2024-01-15T10:30:00Z",
  "level": "INFO",
  "target": "berry_api::loadbalance",
  "message": "Backend selected",
  "fields": {
    "provider": "openai",
    "model": "gpt-4",
    "strategy": "weighted_failover",
    "latency_ms": 850
  }
}
```

**æ—¥å¿—åˆ†æå‘½ä»¤**
```bash
# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
grep "ERROR" logs/berry-api.log | jq .

# ç›‘æ§å¥åº·æ£€æŸ¥
grep "health_check" logs/berry-api.log | tail -20

# åˆ†ææ€§èƒ½æŒ‡æ ‡
grep "latency" logs/berry-api.log | jq '.fields.latency_ms' | sort -n

# ç»Ÿè®¡è¯·æ±‚åˆ†å¸ƒ
grep "Backend selected" logs/berry-api.log | jq -r '.fields.provider' | sort | uniq -c
```

### ğŸš¨ å‘Šè­¦é…ç½®

**Prometheus å‘Šè­¦è§„åˆ™**
```yaml
# alerts.yml
groups:
  - name: berry-api
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"

      - alert: BackendDown
        expr: backend_health_status == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Backend {{ $labels.provider }}:{{ $labels.model }} is down"

      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High latency detected"
```

### ğŸ” å¥åº·æ£€æŸ¥ç›‘æ§

**å¥åº·æ£€æŸ¥ç«¯ç‚¹**
```bash
# åŸºç¡€å¥åº·æ£€æŸ¥
curl http://localhost:3000/health

# è¯¦ç»†å¥åº·çŠ¶æ€
curl http://localhost:3000/metrics | jq .

# ç‰¹å®šåç«¯å¥åº·çŠ¶æ€
curl http://localhost:3000/admin/backend-health
```

**å¥åº·çŠ¶æ€å“åº”ç¤ºä¾‹**
```json
{
  "status": "healthy",
  "timestamp": "2024-01-15T10:30:00Z",
  "providers": {
    "openai": {
      "healthy": true,
      "last_check": "2024-01-15T10:29:45Z",
      "total_requests": 1250,
      "successful_requests": 1200,
      "failed_requests": 50,
      "average_latency_ms": 850,
      "models": {
        "gpt-4": {
          "healthy": true,
          "requests": 800,
          "errors": 20
        }
      }
    }
  },
  "load_balancer": {
    "total_selections": 5000,
    "strategy_distribution": {
      "weighted_failover": 3000,
      "smart_ai": 2000
    }
  }
}
```
   grep "latency" logs/berry-api.log
   ```

### ç”Ÿäº§éƒ¨ç½²

1. **Dockeréƒ¨ç½²**
   ```dockerfile
   FROM rust:1.70 as builder
   WORKDIR /app
   COPY . .
   RUN cargo build --release

   FROM debian:bookworm-slim
   RUN apt-get update && apt-get install -y ca-certificates
   COPY --from=builder /app/target/release/berry-api /usr/local/bin/
   COPY config.toml /etc/berry-api/
   EXPOSE 3000
   CMD ["berry-api"]
   ```

2. **SystemdæœåŠ¡**
   ```ini
   [Unit]
   Description=Berry API Load Balancer
   After=network.target

   [Service]
   Type=simple
   User=berry-api
   WorkingDirectory=/opt/berry-api
   Environment=CONFIG_PATH=/etc/berry-api/config.toml
   Environment=RUST_LOG=info
   ExecStart=/usr/local/bin/berry-api
   Restart=always
   RestartSec=5

   [Install]
   WantedBy=multi-user.target
   ```

3. **è´Ÿè½½å‡è¡¡éƒ¨ç½²**
   - ä½¿ç”¨Nginxæˆ–HAProxyè¿›è¡Œå‰ç«¯è´Ÿè½½å‡è¡¡
   - éƒ¨ç½²å¤šä¸ªBerry APIå®ä¾‹
   - é…ç½®å¥åº·æ£€æŸ¥å’Œæ•…éšœè½¬ç§»

4. **å®‰å…¨é…ç½®**
   - ä½¿ç”¨HTTPSåŠ å¯†ä¼ è¾“
   - å®šæœŸè½®æ¢APIå¯†é’¥
   - é™åˆ¶ç½‘ç»œè®¿é—®æƒé™
   - å¯ç”¨è®¿é—®æ—¥å¿—å®¡è®¡

### æ‰©å±•æ€§

1. **æ°´å¹³æ‰©å±•**
   - æ”¯æŒå¤šå®ä¾‹éƒ¨ç½²
   - æ— çŠ¶æ€è®¾è®¡ï¼Œæ˜“äºæ‰©å±•
   - é…ç½®æ–‡ä»¶å…±äº«

2. **åŠ¨æ€é…ç½®**
   - æ”¯æŒè¿è¡Œæ—¶é…ç½®æ›´æ–°
   - çƒ­é‡è½½Provideré…ç½®
   - åŠ¨æ€æ·»åŠ æ–°æ¨¡å‹

3. **æ’ä»¶åŒ–æ¶æ„**
   - å¯æ‰©å±•çš„è®¤è¯æœºåˆ¶
   - è‡ªå®šä¹‰è´Ÿè½½å‡è¡¡ç­–ç•¥
   - å¯æ’æ‹”çš„ç›‘æ§ç»„ä»¶

## ğŸ”§ æ•…éšœæ’é™¤

### ğŸš¨ å¸¸è§é—®é¢˜è¯Šæ–­

**1. æœåŠ¡å¯åŠ¨å¤±è´¥**
```bash
# æ£€æŸ¥é…ç½®æ–‡ä»¶è¯­æ³•
berry-cli validate-config -c config.toml

# æ£€æŸ¥ç«¯å£å ç”¨
lsof -i :3000
netstat -tulpn | grep :3000

# æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯
RUST_LOG=debug cargo run

# æ£€æŸ¥ä¾èµ–å’Œç¼–è¯‘
cargo check
cargo build --release
```

**2. Providerè¿æ¥å¤±è´¥**
```bash
# æµ‹è¯•ç½‘ç»œè¿æ¥
curl -I https://api.openai.com/v1/models

# éªŒè¯APIå¯†é’¥
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer your-api-key"

# æ£€æŸ¥é˜²ç«å¢™å’Œä»£ç†è®¾ç½®
export https_proxy=http://proxy:8080
```

**3. è®¤è¯å¤±è´¥**
```bash
# éªŒè¯Tokenæ ¼å¼
echo "berry-admin-token-12345" | wc -c

# æ£€æŸ¥ç”¨æˆ·é…ç½®
berry-cli validate-config | grep users

# æµ‹è¯•è®¤è¯
curl -H "Authorization: Bearer berry-admin-token-12345" \
     http://localhost:3000/v1/models
```

**4. è´Ÿè½½å‡è¡¡å¼‚å¸¸**
```bash
# æ£€æŸ¥åç«¯å¥åº·çŠ¶æ€
curl http://localhost:3000/admin/backend-health

# æŸ¥çœ‹è´Ÿè½½å‡è¡¡æƒé‡
curl http://localhost:3000/admin/model-weights

# æµ‹è¯•ç‰¹å®šåç«¯
berry-cli test-backend -p openai -m gpt-4
```

### ğŸ“Š æ—¥å¿—åˆ†æä¸è°ƒè¯•

**æ—¥å¿—çº§åˆ«é…ç½®**
```bash
# åŸºç¡€æ—¥å¿—
export RUST_LOG=info

# è°ƒè¯•ç‰¹å®šæ¨¡å—
export RUST_LOG=berry_loadbalance=debug,berry_relay=debug

# è¯¦ç»†è·Ÿè¸ª
export RUST_LOG=trace
```

**å…³é”®æ—¥å¿—æŸ¥è¯¢**
```bash
# æœåŠ¡å¯åŠ¨æ—¥å¿—
grep "Starting Berry API" logs/berry-api.log

# å¥åº·æ£€æŸ¥çŠ¶æ€
grep "health_check" logs/berry-api.log | tail -20

# è®¤è¯å¤±è´¥è®°å½•
grep "Authentication failed" logs/berry-api.log

# è´Ÿè½½å‡è¡¡å†³ç­–
grep "selected backend" logs/berry-api.log | tail -10

# é”™è¯¯ç»Ÿè®¡
grep "ERROR" logs/berry-api.log | cut -d' ' -f3 | sort | uniq -c

# æ€§èƒ½åˆ†æ
grep "latency" logs/berry-api.log | jq '.fields.latency_ms' | \
  awk '{sum+=$1; count++} END {print "Average:", sum/count "ms"}'
```

### ğŸ”„ é…ç½®çƒ­é‡è½½

Berry API æ”¯æŒè¿è¡Œæ—¶é…ç½®æ›´æ–°ï¼Œæ— éœ€é‡å¯æœåŠ¡ï¼š

**çƒ­é‡è½½æœºåˆ¶**
```bash
# ä¿®æ”¹é…ç½®æ–‡ä»¶
vim config.toml

# å‘é€é‡è½½ä¿¡å·ï¼ˆå¦‚æœæ”¯æŒï¼‰
kill -HUP $(pgrep berry-api)

# æˆ–é€šè¿‡APIé‡è½½ï¼ˆéœ€è¦å®ç°ï¼‰
curl -X POST http://localhost:3000/admin/reload-config \
  -H "Authorization: Bearer admin-token"
```

**é…ç½®å˜æ›´ç›‘æ§**
```bash
# ç›‘æ§é…ç½®æ–‡ä»¶å˜åŒ–
inotifywait -m config.toml -e modify

# éªŒè¯æ–°é…ç½®
berry-cli validate-config -c config.toml

# æ¯”è¾ƒé…ç½®å·®å¼‚
diff config.toml.backup config.toml
```

### ğŸ›¡ï¸ å®‰å…¨æ£€æŸ¥

**é…ç½®å®‰å…¨å®¡è®¡**
```bash
# æ£€æŸ¥æ•æ„Ÿä¿¡æ¯æ³„éœ²
grep -r "sk-" config/ --exclude="*.example"

# éªŒè¯Tokenå¼ºåº¦
python3 -c "
import secrets
token = 'berry-admin-token-12345'
print(f'Token length: {len(token)}')
print(f'Entropy: {len(set(token))} unique chars')
"

# æ£€æŸ¥æ–‡ä»¶æƒé™
ls -la config.toml
# åº”è¯¥æ˜¯ -rw------- (600)
```

### ğŸ” æ€§èƒ½è¯Šæ–­

**å»¶è¿Ÿåˆ†æ**
```bash
# æµ‹è¯•ç«¯åˆ°ç«¯å»¶è¿Ÿ
time curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer token" \
  -d '{"model":"gpt-4","messages":[{"role":"user","content":"hi"}]}'

# åˆ†æå“åº”æ—¶é—´åˆ†å¸ƒ
for i in {1..10}; do
  time curl -s http://localhost:3000/health > /dev/null
done
```

**å†…å­˜å’ŒCPUç›‘æ§**
```bash
# ç›‘æ§èµ„æºä½¿ç”¨
top -p $(pgrep berry-api)
htop -p $(pgrep berry-api)

# å†…å­˜ä½¿ç”¨åˆ†æ
ps aux | grep berry-api
cat /proc/$(pgrep berry-api)/status | grep -E "(VmRSS|VmSize)"
```

## ğŸš€ ç”Ÿäº§éƒ¨ç½²æŒ‡å—

### ğŸ­ ç”Ÿäº§ç¯å¢ƒé…ç½®

**ç³»ç»Ÿè¦æ±‚**
```bash
# æ¨èé…ç½®
CPU: 2æ ¸å¿ƒä»¥ä¸Š
å†…å­˜: 2GBä»¥ä¸Š
ç£ç›˜: 10GBä»¥ä¸Š
ç½‘ç»œ: ç¨³å®šçš„äº’è”ç½‘è¿æ¥

# æ“ä½œç³»ç»Ÿ
Ubuntu 22.04 LTS (æ¨è)
CentOS 8+
Debian 11+
```

**ç¯å¢ƒå˜é‡é…ç½®**
```bash
# /etc/environment
RUST_LOG=info
CONFIG_PATH=/etc/berry-api/config.toml
BIND_ADDRESS=0.0.0.0:3000
MAX_CONNECTIONS=1000
```

### ğŸ³ Docker ç”Ÿäº§éƒ¨ç½²

**æ¨èï¼šé¢„ç¼–è¯‘æ„å»ºï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰**
```bash
# CI/CD æµæ°´çº¿ä¸­çš„æ„å»ºæ­¥éª¤
cargo build --workspace --release --features observability --target x86_64-unknown-linux-gnu
mkdir -p ./docker-binaries
cp target/x86_64-unknown-linux-gnu/release/berry-api ./docker-binaries/
cp target/x86_64-unknown-linux-gnu/release/berry-cli ./docker-binaries/
docker build -f Dockerfile.prebuilt -t berry-api:prod .
```

**å¤‡é€‰ï¼šä¼ ç»Ÿå¤šé˜¶æ®µæ„å»º**
```dockerfile
# Dockerfile (å·²ä¼˜åŒ–)
FROM rust:1.87-slim-bookworm AS builder
WORKDIR /app
COPY . .
RUN cargo build --workspace --release --features observability

FROM gcr.io/distroless/cc-debian12
WORKDIR /app
COPY --from=builder /app/target/release/berry-api /usr/local/bin/
COPY --from=builder /app/target/release/berry-cli /usr/local/bin/
EXPOSE 3000
CMD ["/usr/local/bin/berry-api"]
```

**Docker Compose ç”Ÿäº§é…ç½®**
```yaml
# docker-compose.prod.yml
version: '3.8'
services:
  berry-api:
    build:
      context: .
      dockerfile: Dockerfile.prod
    ports:
      - "3000:3000"
    environment:
      - RUST_LOG=info
      - CONFIG_PATH=/app/config.toml
    volumes:
      - ./config.toml:/app/config.toml:ro
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - berry-api
    restart: unless-stopped
```

### âš–ï¸ è´Ÿè½½å‡è¡¡ä¸é«˜å¯ç”¨

**Nginx é…ç½®**
```nginx
# nginx.conf
upstream berry_api {
    server berry-api-1:3000 weight=3;
    server berry-api-2:3000 weight=2;
    server berry-api-3:3000 weight=1 backup;
}

server {
    listen 80;
    listen 443 ssl http2;
    server_name api.yourdomain.com;

    # SSLé…ç½®
    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;

    # å®‰å…¨å¤´
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";

    location / {
        proxy_pass http://berry_api;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # è¶…æ—¶é…ç½®
        proxy_connect_timeout 30s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;

        # ç¼“å†²é…ç½®
        proxy_buffering on;
        proxy_buffer_size 4k;
        proxy_buffers 8 4k;
    }

    # å¥åº·æ£€æŸ¥
    location /health {
        proxy_pass http://berry_api/health;
        access_log off;
    }
}
```

### ğŸ”’ å®‰å…¨æœ€ä½³å®è·µ

**1. APIå¯†é’¥ç®¡ç†**
```bash
# ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†æœåŠ¡
export OPENAI_API_KEY=$(vault kv get -field=api_key secret/openai)

# å®šæœŸè½®æ¢å¯†é’¥
./scripts/rotate-api-keys.sh

# å¯†é’¥å¼ºåº¦æ£€æŸ¥
python3 -c "
import secrets
import string
# ç”Ÿæˆå¼ºå¯†é’¥
key = ''.join(secrets.choice(string.ascii_letters + string.digits) for _ in range(32))
print(f'Strong API key: berry-{key}')
"
```

**2. ç½‘ç»œå®‰å…¨**
```bash
# é˜²ç«å¢™é…ç½®
ufw allow 22/tcp
ufw allow 80/tcp
ufw allow 443/tcp
ufw deny 3000/tcp  # åªå…è®¸å†…éƒ¨è®¿é—®
ufw enable

# é™åˆ¶è®¿é—®æº
iptables -A INPUT -p tcp --dport 3000 -s 10.0.0.0/8 -j ACCEPT
iptables -A INPUT -p tcp --dport 3000 -j DROP
```

**3. æ—¥å¿—å®‰å…¨**
```toml
# config.toml - ç”Ÿäº§é…ç½®
[settings]
# ä¸è®°å½•æ•æ„Ÿä¿¡æ¯
log_request_body = false
log_response_body = false
mask_api_keys = true
```

### ğŸ“Š ç›‘æ§ä¸å‘Šè­¦

**Prometheus + Grafana éƒ¨ç½²**
```yaml
# monitoring/docker-compose.yml
version: '3.8'
services:
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'

  grafana:
    image: grafana/grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources

volumes:
  prometheus_data:
  grafana_data:
```

### ğŸ”„ CI/CD æµæ°´çº¿

**GitHub Actions é…ç½®**
```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
      - run: cargo test --all-features

  build:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Build Docker image
        run: |
          docker build -t berry-api:${{ github.sha }} .
          docker tag berry-api:${{ github.sha }} berry-api:latest

      - name: Push to registry
        run: |
          echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin
          docker push berry-api:${{ github.sha }}
          docker push berry-api:latest

  deploy:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to production
        run: |
          ssh ${{ secrets.PROD_SERVER }} "
            docker pull berry-api:latest
            docker-compose -f docker-compose.prod.yml up -d --no-deps berry-api
          "
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

### ğŸ› ï¸ å¼€å‘ç¯å¢ƒè®¾ç½®

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/PPKunOfficial/berry-api.git
cd berry-api

# 2. å®‰è£…Rustå·¥å…·é“¾
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup component add clippy rustfmt

# 3. å®‰è£…ä¾èµ–å¹¶ç¼–è¯‘
cargo build

# 4. è¿è¡Œæµ‹è¯•
cargo test --all-features

# 5. ä»£ç è´¨é‡æ£€æŸ¥
cargo fmt --check
cargo clippy -- -D warnings

# 6. è¿è¡Œå¼€å‘æœåŠ¡å™¨
RUST_LOG=debug cargo run
```

### ğŸ“ å¼€å‘è§„èŒƒ

**ä»£ç é£æ ¼**
```bash
# æ ¼å¼åŒ–ä»£ç 
cargo fmt

# æ£€æŸ¥ä»£ç è´¨é‡
cargo clippy

# è¿è¡Œæ‰€æœ‰æ£€æŸ¥
./scripts/check.sh
```

**æäº¤è§„èŒƒ**
```bash
# æäº¤æ ¼å¼
git commit -m "feat: add SmartAI load balancing strategy"
git commit -m "fix: resolve authentication timeout issue"
git commit -m "docs: update API documentation"

# æäº¤ç±»å‹
feat: æ–°åŠŸèƒ½
fix: ä¿®å¤bug
docs: æ–‡æ¡£æ›´æ–°
style: ä»£ç æ ¼å¼
refactor: é‡æ„
test: æµ‹è¯•ç›¸å…³
chore: æ„å»º/å·¥å…·ç›¸å…³
```

**Pull Request æµç¨‹**
1. Fork é¡¹ç›®åˆ°ä¸ªäººä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ï¼š`git checkout -b feature/new-feature`
3. æäº¤æ›´æ”¹ï¼š`git commit -am 'Add new feature'`
4. æ¨é€åˆ†æ”¯ï¼š`git push origin feature/new-feature`
5. åˆ›å»º Pull Request

### ğŸ§ª æµ‹è¯•æŒ‡å—

**å•å…ƒæµ‹è¯•**
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
cargo test

# è¿è¡Œç‰¹å®šæ¨¡å—æµ‹è¯•
cargo test loadbalance
cargo test auth

# ç”Ÿæˆæµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š
cargo tarpaulin --out Html
```

**é›†æˆæµ‹è¯•**
```bash
# å¯åŠ¨æµ‹è¯•ç¯å¢ƒ
docker-compose -f docker-compose.test.yml up -d

# è¿è¡Œé›†æˆæµ‹è¯•
cargo test --test integration

# æ¸…ç†æµ‹è¯•ç¯å¢ƒ
docker-compose -f docker-compose.test.yml down
```

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼æˆ‘ä»¬é‡è§†æ¯ä¸€ä¸ªè´¡çŒ®ã€‚

## ï¿½ å¸¸è§ç”¨ä¾‹

### ğŸ¢ ä¼ä¸šçº§AIæœåŠ¡

**åœºæ™¯ï¼šå¤§å‹ä¼ä¸šå¤šéƒ¨é—¨AIæœåŠ¡**
```toml
# ä¼ä¸šé…ç½®ç¤ºä¾‹
[settings]
health_check_interval_seconds = 30
max_internal_retries = 3

# éƒ¨é—¨ç”¨æˆ·é…ç½®
[users.hr_dept]
name = "HR Department"
token = "hr-dept-token-12345"
allowed_models = ["gpt-3.5-turbo", "claude-3-haiku"]
tags = ["hr", "basic"]

[users.rd_dept]
name = "R&D Department"
token = "rd-dept-token-67890"
allowed_models = ["gpt-4", "claude-3-opus"]
tags = ["rd", "premium"]

# æˆæœ¬ä¼˜åŒ–é…ç½®
[models.cost_effective]
name = "cost-effective"
strategy = "smart_ai"
enabled = true

[[models.cost_effective.backends]]
provider = "cheap_provider"
model = "gpt-3.5-turbo"
weight = 0.8
billing_mode = "per_request"
tags = []

[[models.cost_effective.backends]]
provider = "premium_provider"
model = "gpt-4"
weight = 0.2
billing_mode = "per_token"
tags = ["premium"]
```

### ğŸš€ åˆåˆ›å…¬å¸æˆæœ¬æ§åˆ¶

**åœºæ™¯ï¼šé¢„ç®—æœ‰é™çš„åˆåˆ›å…¬å¸**
```toml
# æˆæœ¬æ•æ„Ÿé…ç½®
[models.startup_gpt4]
name = "gpt-4"
strategy = "smart_ai"  # æ™ºèƒ½æˆæœ¬æ§åˆ¶
enabled = true

[[models.startup_gpt4.backends]]
provider = "budget_provider"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 1
enabled = true

[[models.startup_gpt4.backends]]
provider = "premium_provider"
model = "gpt-4"
weight = 0.1  # ä»…ä½œä¸ºå¤‡é€‰
priority = 2
enabled = true
tags = ["premium"]
```

### ğŸ”„ å¤šäº‘å®¹ç¾éƒ¨ç½²

**åœºæ™¯ï¼šè·¨äº‘æœåŠ¡å•†çš„é«˜å¯ç”¨éƒ¨ç½²**
```toml
[models.ha_gpt4]
name = "gpt-4"
strategy = "weighted_failover"
enabled = true

# ä¸»è¦äº‘æœåŠ¡å•†
[[models.ha_gpt4.backends]]
provider = "aws_openai"
model = "gpt-4"
weight = 0.5
priority = 1
enabled = true

# å¤‡ç”¨äº‘æœåŠ¡å•†
[[models.ha_gpt4.backends]]
provider = "azure_openai"
model = "gpt-4"
weight = 0.3
priority = 2
enabled = true

# åº”æ€¥æœåŠ¡å•†
[[models.ha_gpt4.backends]]
provider = "gcp_openai"
model = "gpt-4"
weight = 0.2
priority = 3
enabled = true
```

### ğŸ§ª å¼€å‘æµ‹è¯•ç¯å¢ƒ

**åœºæ™¯ï¼šå¼€å‘å›¢é˜Ÿæµ‹è¯•ä¸åŒAIæ¨¡å‹**
```toml
[users.dev_team]
name = "Development Team"
token = "dev-team-token"
allowed_models = []  # å…è®¸è®¿é—®æ‰€æœ‰æ¨¡å‹
enabled = true
tags = ["dev", "testing"]

# æµ‹è¯•æ¨¡å‹é…ç½®
[models.test_model]
name = "test-model"
strategy = "round_robin"  # è½®è¯¢æµ‹è¯•æ‰€æœ‰åç«¯
enabled = true

[[models.test_model.backends]]
provider = "openai"
model = "gpt-3.5-turbo"
weight = 1.0
enabled = true

[[models.test_model.backends]]
provider = "anthropic"
model = "claude-3-sonnet"
weight = 1.0
enabled = true
```

## ğŸ¯ æœ€ä½³å®è·µæ€»ç»“

### âœ… é…ç½®æœ€ä½³å®è·µ

1. **å®‰å…¨é…ç½®**
   - ä½¿ç”¨å¼ºéšæœºToken
   - å®šæœŸè½®æ¢APIå¯†é’¥
   - é™åˆ¶ç”¨æˆ·æ¨¡å‹è®¿é—®æƒé™
   - å¯ç”¨è¯·æ±‚æ—¥å¿—å®¡è®¡

2. **æ€§èƒ½ä¼˜åŒ–**
   - æ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µè°ƒæ•´æƒé‡
   - è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
   - ä½¿ç”¨SmartAIç­–ç•¥è¿›è¡Œæˆæœ¬ä¼˜åŒ–
   - å¯ç”¨å¥åº·æ£€æŸ¥å’Œç†”æ–­æœºåˆ¶

3. **ç›‘æ§å‘Šè­¦**
   - é…ç½®PrometheusæŒ‡æ ‡æ”¶é›†
   - è®¾ç½®å…³é”®æŒ‡æ ‡å‘Šè­¦
   - å®šæœŸæ£€æŸ¥æ—¥å¿—å’Œæ€§èƒ½
   - ç›‘æ§æˆæœ¬å’Œä½¿ç”¨æƒ…å†µ

### ğŸš€ éƒ¨ç½²æœ€ä½³å®è·µ

1. **ç”Ÿäº§ç¯å¢ƒ**
   - ä½¿ç”¨Dockerå®¹å™¨åŒ–éƒ¨ç½²
   - é…ç½®è´Ÿè½½å‡è¡¡å’Œé«˜å¯ç”¨
   - å¯ç”¨HTTPSå’Œå®‰å…¨å¤´
   - å®æ–½å¤‡ä»½å’Œæ¢å¤ç­–ç•¥

2. **æ‰©å±•æ€§**
   - è®¾è®¡æ— çŠ¶æ€æ¶æ„
   - æ”¯æŒæ°´å¹³æ‰©å±•
   - ä½¿ç”¨é…ç½®çƒ­é‡è½½
   - å®æ–½è“ç»¿éƒ¨ç½²

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ **GNU General Public License v3.0** è®¸å¯è¯ã€‚

è¿™æ„å‘³ç€ï¼š
- âœ… å¯ä»¥è‡ªç”±ä½¿ç”¨ã€ä¿®æ”¹å’Œåˆ†å‘
- âœ… å¯ä»¥ç”¨äºå•†ä¸šç”¨é€”
- âš ï¸ ä¿®æ”¹åçš„ä»£ç å¿…é¡»å¼€æº
- âš ï¸ å¿…é¡»ä¿ç•™åŸå§‹è®¸å¯è¯å£°æ˜

è¯¦ç»†ä¿¡æ¯è¯·æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ”— ç›¸å…³èµ„æº

### ğŸ“š å®˜æ–¹æ–‡æ¡£
- [OpenAI API å‚è€ƒ](https://platform.openai.com/docs/api-reference) - OpenAIå®˜æ–¹APIæ–‡æ¡£
- [Azure OpenAI æœåŠ¡](https://docs.microsoft.com/en-us/azure/cognitive-services/openai/) - å¾®è½¯Azure OpenAIæ–‡æ¡£
- [Anthropic Claude API](https://docs.anthropic.com/claude/reference/) - Anthropicå®˜æ–¹APIæ–‡æ¡£

### ğŸ› ï¸ æŠ€æœ¯æ ˆ
- [Rust ç¼–ç¨‹è¯­è¨€](https://www.rust-lang.org/) - ç³»ç»Ÿçº§ç¼–ç¨‹è¯­è¨€
- [Tokio å¼‚æ­¥è¿è¡Œæ—¶](https://tokio.rs/) - Rustå¼‚æ­¥ç¼–ç¨‹æ¡†æ¶
- [Axum Webæ¡†æ¶](https://github.com/tokio-rs/axum) - ç°ä»£åŒ–WebæœåŠ¡æ¡†æ¶
- [Serde åºåˆ—åŒ–](https://serde.rs/) - Ruståºåˆ—åŒ–/ååºåˆ—åŒ–æ¡†æ¶
- [TOML é…ç½®æ ¼å¼](https://toml.io/) - äººæ€§åŒ–çš„é…ç½®æ–‡ä»¶æ ¼å¼

### ğŸ”§ å·¥å…·ä¸é›†æˆ
- [Prometheus ç›‘æ§](https://prometheus.io/) - å¼€æºç›‘æ§ç³»ç»Ÿ
- [Grafana å¯è§†åŒ–](https://grafana.com/) - ç›‘æ§æ•°æ®å¯è§†åŒ–å¹³å°
- [Docker å®¹å™¨åŒ–](https://www.docker.com/) - åº”ç”¨å®¹å™¨åŒ–å¹³å°
- [Nginx è´Ÿè½½å‡è¡¡](https://nginx.org/) - é«˜æ€§èƒ½WebæœåŠ¡å™¨

### ğŸŒŸ ç¤¾åŒºä¸æ”¯æŒ
- [GitHub ä»“åº“](https://github.com/PPKunOfficial/berry-api) - æºä»£ç å’Œç‰ˆæœ¬ç®¡ç†
- [Issues é—®é¢˜åé¦ˆ](https://github.com/PPKunOfficial/berry-api/issues) - BugæŠ¥å‘Šå’ŒåŠŸèƒ½è¯·æ±‚
- [Discussions è®¨è®ºåŒº](https://github.com/PPKunOfficial/berry-api/discussions) - ç¤¾åŒºè®¨è®ºå’Œäº¤æµ
- [Wiki æ–‡æ¡£](https://github.com/PPKunOfficial/berry-api/wiki) - è¯¦ç»†æ–‡æ¡£å’Œæ•™ç¨‹

### ğŸ“ˆ æ€§èƒ½åŸºå‡†
- **å¹¶å‘å¤„ç†**: æ”¯æŒ1000+å¹¶å‘è¿æ¥
- **å“åº”å»¶è¿Ÿ**: å¹³å‡å¢åŠ å»¶è¿Ÿ<10ms
- **å†…å­˜å ç”¨**: åŸºç¡€è¿è¡Œå†…å­˜<100MB
- **CPUä½¿ç”¨**: å•æ ¸å¿ƒå¯å¤„ç†500+ QPS

---

<div align="center">

## ğŸš€ Berry API

**è®©AIæœåŠ¡è´Ÿè½½å‡è¡¡å˜å¾—ç®€å•é«˜æ•ˆï¼**

[![Star on GitHub](https://img.shields.io/github/stars/PPKunOfficial/berry-api?style=social)](https://github.com/PPKunOfficial/berry-api)
[![Fork on GitHub](https://img.shields.io/github/forks/PPKunOfficial/berry-api?style=social)](https://github.com/PPKunOfficial/berry-api/fork)

**[å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)** â€¢ **[é…ç½®æŒ‡å—](#-é…ç½®æŒ‡å—)** â€¢ **[APIæ–‡æ¡£](#-apiä½¿ç”¨æŒ‡å—)** â€¢ **[éƒ¨ç½²æŒ‡å—](#-ç”Ÿäº§éƒ¨ç½²æŒ‡å—)**

</div>
