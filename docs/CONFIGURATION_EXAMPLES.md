# Berry API é…ç½®ç¤ºä¾‹é›†åˆ

æœ¬æ–‡æ¡£æä¾›äº†å„ç§åœºæ™¯ä¸‹çš„Berry APIé…ç½®ç¤ºä¾‹ï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿé…ç½®é€‚åˆæ‚¨éœ€æ±‚çš„è´Ÿè½½å‡è¡¡æ–¹æ¡ˆã€‚

## ğŸ“‹ ç›®å½•

- [åŸºç¡€é…ç½®](#åŸºç¡€é…ç½®)
- [ä¼ä¸šçº§é…ç½®](#ä¼ä¸šçº§é…ç½®)
- [é«˜å¯ç”¨é…ç½®](#é«˜å¯ç”¨é…ç½®)
- [æˆæœ¬ä¼˜åŒ–é…ç½®](#æˆæœ¬ä¼˜åŒ–é…ç½®)
- [å¼€å‘æµ‹è¯•é…ç½®](#å¼€å‘æµ‹è¯•é…ç½®)
- [å¤šåœ°åŸŸé…ç½®](#å¤šåœ°åŸŸé…ç½®)

## ğŸš€ åŸºç¡€é…ç½®

### å•Providerç®€å•é…ç½®

é€‚ç”¨äºåˆšå¼€å§‹ä½¿ç”¨æˆ–ç®€å•åœºæ™¯ï¼š

```toml
# config_simple.toml
[settings]
health_check_interval_seconds = 30
request_timeout_seconds = 30
max_retries = 3

[users.admin]
name = "Administrator"
token = "admin-token-123456"
allowed_models = []
enabled = true

[providers.openai]
name = "OpenAI"
base_url = "https://api.openai.com/v1"
api_key = "sk-your-openai-key-here"
models = ["gpt-4", "gpt-3.5-turbo"]
enabled = true
timeout_seconds = 30
max_retries = 3

[models.gpt_4]
name = "gpt-4"
strategy = "random"
enabled = true

[[models.gpt_4.backends]]
provider = "openai"
model = "gpt-4"
weight = 1.0
priority = 1
enabled = true

[models.gpt_3_5_turbo]
name = "gpt-3.5-turbo"
strategy = "random"
enabled = true

[[models.gpt_3_5_turbo.backends]]
provider = "openai"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 1
enabled = true
```

### åŒProviderè´Ÿè½½å‡è¡¡

é€‚ç”¨äºéœ€è¦åŸºæœ¬è´Ÿè½½å‡è¡¡çš„åœºæ™¯ï¼š

```toml
# config_dual_provider.toml
[settings]
health_check_interval_seconds = 30
request_timeout_seconds = 30
max_retries = 3
circuit_breaker_failure_threshold = 5
circuit_breaker_timeout_seconds = 60

[users.admin]
name = "Administrator"
token = "admin-secure-token-789"
allowed_models = []
enabled = true

[providers.openai_primary]
name = "OpenAI Primary"
base_url = "https://api.openai.com/v1"
api_key = "sk-your-primary-key"
models = ["gpt-4", "gpt-3.5-turbo"]
enabled = true
timeout_seconds = 30
max_retries = 3

[providers.openai_backup]
name = "OpenAI Backup"
base_url = "https://api.openai.com/v1"
api_key = "sk-your-backup-key"
models = ["gpt-4", "gpt-3.5-turbo"]
enabled = true
timeout_seconds = 30
max_retries = 3

[models.gpt_4]
name = "gpt-4"
strategy = "weighted_random"
enabled = true

[[models.gpt_4.backends]]
provider = "openai_primary"
model = "gpt-4"
weight = 0.7
priority = 1
enabled = true

[[models.gpt_4.backends]]
provider = "openai_backup"
model = "gpt-4"
weight = 0.3
priority = 2
enabled = true

[models.gpt_3_5_turbo]
name = "gpt-3.5-turbo"
strategy = "round_robin"
enabled = true

[[models.gpt_3_5_turbo.backends]]
provider = "openai_primary"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 1
enabled = true

[[models.gpt_3_5_turbo.backends]]
provider = "openai_backup"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 2
enabled = true
```

## ğŸ¢ ä¼ä¸šçº§é…ç½®

### å¤šç§Ÿæˆ·æƒé™ç®¡ç†

é€‚ç”¨äºéœ€è¦ä¸ºä¸åŒç”¨æˆ·ç¾¤ä½“æä¾›ä¸åŒæœåŠ¡çš„ä¼ä¸šï¼š

```toml
# config_enterprise.toml
[settings]
health_check_interval_seconds = 30
request_timeout_seconds = 30
max_retries = 3
circuit_breaker_failure_threshold = 5
circuit_breaker_timeout_seconds = 60

# ===== ç”¨æˆ·æƒé™é…ç½® =====

# ç³»ç»Ÿç®¡ç†å‘˜ - å®Œå…¨è®¿é—®æƒé™
[users.admin]
name = "System Administrator"
token = "admin-enterprise-token-super-secure"
allowed_models = []  # ç©ºæ•°ç»„è¡¨ç¤ºè®¿é—®æ‰€æœ‰æ¨¡å‹
enabled = true
tags = ["admin", "unlimited"]

# åŸºç¡€ç”¨æˆ· - åªèƒ½ä½¿ç”¨ç»æµå‹æ¨¡å‹
[users.basic_tier]
name = "Basic Tier User"
token = "basic-user-token-12345"
allowed_models = ["economy-chat", "basic-assistant"]
enabled = true
tags = ["basic", "limited"]

# æ ‡å‡†ç”¨æˆ· - å¯ä»¥ä½¿ç”¨ä¸­çº§æ¨¡å‹
[users.standard_tier]
name = "Standard Tier User"
token = "standard-user-token-67890"
allowed_models = ["standard-chat", "gpt-3.5-turbo", "fast-response"]
enabled = true
tags = ["standard", "moderate"]

# é«˜çº§ç”¨æˆ· - å¯ä»¥ä½¿ç”¨é«˜çº§æ¨¡å‹
[users.premium_tier]
name = "Premium Tier User"
token = "premium-user-token-abcdef"
allowed_models = ["premium-chat", "gpt-4", "claude-3", "advanced-assistant"]
enabled = true
tags = ["premium", "advanced"]

# ä¼ä¸šç”¨æˆ· - å¯ä»¥ä½¿ç”¨æ‰€æœ‰æ¨¡å‹
[users.enterprise_tier]
name = "Enterprise Tier User"
token = "enterprise-user-token-xyz789"
allowed_models = []  # è®¿é—®æ‰€æœ‰æ¨¡å‹
enabled = true
tags = ["enterprise", "unlimited"]

# ===== Provideré…ç½® =====

[providers.openai_primary]
name = "OpenAI Primary Account"
base_url = "https://api.openai.com/v1"
api_key = "sk-openai-primary-key"
models = ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"]
enabled = true
timeout_seconds = 30
max_retries = 3

[providers.openai_secondary]
name = "OpenAI Secondary Account"
base_url = "https://api.openai.com/v1"
api_key = "sk-openai-secondary-key"
models = ["gpt-4", "gpt-3.5-turbo"]
enabled = true
timeout_seconds = 30
max_retries = 3

[providers.azure_openai]
name = "Azure OpenAI Enterprise"
base_url = "https://your-enterprise.openai.azure.com"
api_key = "azure-enterprise-key"
models = ["gpt-4", "gpt-35-turbo"]
enabled = true
timeout_seconds = 45
max_retries = 2
[providers.azure_openai.headers]
"api-version" = "2024-02-01"

[providers.anthropic]
name = "Anthropic Claude"
base_url = "https://api.anthropic.com"
api_key = "sk-ant-anthropic-key"
models = ["claude-3-opus-20240229", "claude-3-sonnet-20240229"]
enabled = true
timeout_seconds = 60
max_retries = 2

[providers.budget_proxy]
name = "Budget Proxy Service"
base_url = "https://budget-proxy.example.com/v1"
api_key = "budget-proxy-key"
models = ["gpt-3.5-turbo", "gpt-4"]
enabled = true
timeout_seconds = 20
max_retries = 3

# ===== æ¨¡å‹æ˜ å°„é…ç½® =====

# ç»æµå‹èŠå¤© - åŸºç¡€ç”¨æˆ·ä½¿ç”¨
[models.economy_chat]
name = "economy-chat"
strategy = "weighted_random"
enabled = true

[[models.economy_chat.backends]]
provider = "budget_proxy"
model = "gpt-3.5-turbo"
weight = 0.8
priority = 1
enabled = true

[[models.economy_chat.backends]]
provider = "openai_secondary"
model = "gpt-3.5-turbo"
weight = 0.2
priority = 2
enabled = true

# æ ‡å‡†èŠå¤© - æ ‡å‡†ç”¨æˆ·ä½¿ç”¨
[models.standard_chat]
name = "standard-chat"
strategy = "round_robin"
enabled = true

[[models.standard_chat.backends]]
provider = "openai_primary"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 1
enabled = true

[[models.standard_chat.backends]]
provider = "openai_secondary"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 2
enabled = true

# é«˜çº§èŠå¤© - é«˜çº§ç”¨æˆ·ä½¿ç”¨
[models.premium_chat]
name = "premium-chat"
strategy = "least_latency"
enabled = true

[[models.premium_chat.backends]]
provider = "openai_primary"
model = "gpt-4"
weight = 1.0
priority = 1
enabled = true

[[models.premium_chat.backends]]
provider = "azure_openai"
model = "gpt-4"
weight = 1.0
priority = 2
enabled = true

# Claude-3 é«˜çº§æ¨¡å‹
[models.claude_3]
name = "claude-3"
strategy = "failover"
enabled = true

[[models.claude_3.backends]]
provider = "anthropic"
model = "claude-3-opus-20240229"
weight = 1.0
priority = 1
enabled = true

[[models.claude_3.backends]]
provider = "anthropic"
model = "claude-3-sonnet-20240229"
weight = 1.0
priority = 2
enabled = true

# åŸºç¡€åŠ©æ‰‹
[models.basic_assistant]
name = "basic-assistant"
strategy = "random"
enabled = true

[[models.basic_assistant.backends]]
provider = "budget_proxy"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 1
enabled = true

# é«˜çº§åŠ©æ‰‹
[models.advanced_assistant]
name = "advanced-assistant"
strategy = "weighted_failover"
enabled = true

[[models.advanced_assistant.backends]]
provider = "openai_primary"
model = "gpt-4-turbo"
weight = 0.6
priority = 1
enabled = true

[[models.advanced_assistant.backends]]
provider = "anthropic"
model = "claude-3-opus-20240229"
weight = 0.4
priority = 2
enabled = true

# å¿«é€Ÿå“åº”æ¨¡å‹
[models.fast_response]
name = "fast-response"
strategy = "least_latency"
enabled = true

[[models.fast_response.backends]]
provider = "openai_primary"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 1
enabled = true

[[models.fast_response.backends]]
provider = "budget_proxy"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 2
enabled = true

# æ ‡å‡†GPT-4è®¿é—®
[models.gpt_4]
name = "gpt-4"
strategy = "weighted_random"
enabled = true

[[models.gpt_4.backends]]
provider = "openai_primary"
model = "gpt-4"
weight = 0.5
priority = 1
enabled = true

[[models.gpt_4.backends]]
provider = "azure_openai"
model = "gpt-4"
weight = 0.3
priority = 2
enabled = true

[[models.gpt_4.backends]]
provider = "openai_secondary"
model = "gpt-4"
weight = 0.2
priority = 3
enabled = true

# æ ‡å‡†GPT-3.5è®¿é—®
[models.gpt_3_5_turbo]
name = "gpt-3.5-turbo"
strategy = "round_robin"
enabled = true

[[models.gpt_3_5_turbo.backends]]
provider = "openai_primary"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 1
enabled = true

[[models.gpt_3_5_turbo.backends]]
provider = "openai_secondary"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 2
enabled = true
```

## ğŸ¥ é«˜å¯ç”¨é…ç½®

### æ•…éšœè½¬ç§»ä¼˜å…ˆé…ç½®

é€‚ç”¨äºå¯¹å¯ç”¨æ€§è¦æ±‚æé«˜çš„ç”Ÿäº§ç¯å¢ƒï¼š

```toml
# config_high_availability.toml
[settings]
health_check_interval_seconds = 15  # æ›´é¢‘ç¹çš„å¥åº·æ£€æŸ¥
request_timeout_seconds = 30
max_retries = 5  # æ›´å¤šé‡è¯•æ¬¡æ•°
circuit_breaker_failure_threshold = 3  # æ›´å¿«çš„ç†”æ–­
circuit_breaker_timeout_seconds = 30   # æ›´å¿«çš„æ¢å¤

[users.admin]
name = "HA Administrator"
token = "ha-admin-token-ultra-secure"
allowed_models = []
enabled = true

# ä¸»Provider - æœ€é«˜ä¼˜å…ˆçº§
[providers.primary_openai]
name = "Primary OpenAI"
base_url = "https://api.openai.com/v1"
api_key = "sk-primary-key"
models = ["gpt-4", "gpt-3.5-turbo"]
enabled = true
timeout_seconds = 25
max_retries = 3

# å¤‡ç”¨Provider 1 - Azure
[providers.backup_azure]
name = "Backup Azure OpenAI"
base_url = "https://backup.openai.azure.com"
api_key = "azure-backup-key"
models = ["gpt-4", "gpt-35-turbo"]
enabled = true
timeout_seconds = 30
max_retries = 3
[providers.backup_azure.headers]
"api-version" = "2024-02-01"

# å¤‡ç”¨Provider 2 - ç¬¬äºŒä¸ªOpenAIè´¦æˆ·
[providers.backup_openai]
name = "Backup OpenAI"
base_url = "https://api.openai.com/v1"
api_key = "sk-backup-key"
models = ["gpt-4", "gpt-3.5-turbo"]
enabled = true
timeout_seconds = 25
max_retries = 3

# åº”æ€¥Provider - ä»£ç†æœåŠ¡
[providers.emergency_proxy]
name = "Emergency Proxy"
base_url = "https://emergency-proxy.example.com/v1"
api_key = "emergency-proxy-key"
models = ["gpt-4", "gpt-3.5-turbo"]
enabled = true
timeout_seconds = 20
max_retries = 2

# é«˜å¯ç”¨GPT-4é…ç½®
[models.gpt_4_ha]
name = "gpt-4"
strategy = "failover"
enabled = true

[[models.gpt_4_ha.backends]]
provider = "primary_openai"
model = "gpt-4"
weight = 1.0
priority = 1  # æœ€é«˜ä¼˜å…ˆçº§
enabled = true

[[models.gpt_4_ha.backends]]
provider = "backup_azure"
model = "gpt-4"
weight = 1.0
priority = 2  # ç¬¬äºŒä¼˜å…ˆçº§
enabled = true

[[models.gpt_4_ha.backends]]
provider = "backup_openai"
model = "gpt-4"
weight = 1.0
priority = 3  # ç¬¬ä¸‰ä¼˜å…ˆçº§
enabled = true

[[models.gpt_4_ha.backends]]
provider = "emergency_proxy"
model = "gpt-4"
weight = 1.0
priority = 4  # åº”æ€¥ä½¿ç”¨
enabled = true

# é«˜å¯ç”¨GPT-3.5é…ç½®
[models.gpt_3_5_turbo_ha]
name = "gpt-3.5-turbo"
strategy = "failover"
enabled = true

[[models.gpt_3_5_turbo_ha.backends]]
provider = "primary_openai"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 1
enabled = true

[[models.gpt_3_5_turbo_ha.backends]]
provider = "backup_azure"
model = "gpt-35-turbo"
weight = 1.0
priority = 2
enabled = true

[[models.gpt_3_5_turbo_ha.backends]]
provider = "backup_openai"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 3
enabled = true

[[models.gpt_3_5_turbo_ha.backends]]
provider = "emergency_proxy"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 4
enabled = true
```

## ğŸ’° æˆæœ¬ä¼˜åŒ–é…ç½®

### æˆæœ¬æ•æ„Ÿå‹é…ç½®

é€‚ç”¨äºéœ€è¦æ§åˆ¶æˆæœ¬ä½†ä¿è¯åŸºæœ¬å¯ç”¨æ€§çš„åœºæ™¯ï¼š

```toml
# config_cost_optimized.toml
[settings]
health_check_interval_seconds = 60  # é™ä½æ£€æŸ¥é¢‘ç‡èŠ‚çœèµ„æº
request_timeout_seconds = 45        # ç¨é•¿çš„è¶…æ—¶æ—¶é—´
max_retries = 2                     # å‡å°‘é‡è¯•æ¬¡æ•°
circuit_breaker_failure_threshold = 10  # æ›´å®½æ¾çš„ç†”æ–­æ¡ä»¶
circuit_breaker_timeout_seconds = 120   # æ›´é•¿çš„æ¢å¤æ—¶é—´

[users.cost_user]
name = "Cost Conscious User"
token = "cost-user-token-123"
allowed_models = ["economy", "budget-chat", "cheap-assistant"]
enabled = true

# ä¾¿å®œçš„ä»£ç†æœåŠ¡ - ä¸»è¦ä½¿ç”¨
[providers.cheap_proxy]
name = "Cheap Proxy Service"
base_url = "https://cheap-proxy.example.com/v1"
api_key = "cheap-proxy-key"
models = ["gpt-3.5-turbo", "gpt-4"]
enabled = true
timeout_seconds = 30
max_retries = 2

# ä¸­ç­‰ä»·æ ¼çš„ä»£ç† - å¤‡ç”¨
[providers.medium_proxy]
name = "Medium Price Proxy"
base_url = "https://medium-proxy.example.com/v1"
api_key = "medium-proxy-key"
models = ["gpt-3.5-turbo", "gpt-4"]
enabled = true
timeout_seconds = 25
max_retries = 2

# å®˜æ–¹æœåŠ¡ - åº”æ€¥ä½¿ç”¨
[providers.official_backup]
name = "Official Backup"
base_url = "https://api.openai.com/v1"
api_key = "sk-official-backup-key"
models = ["gpt-3.5-turbo", "gpt-4"]
enabled = true
timeout_seconds = 30
max_retries = 1

# ç»æµå‹æ¨¡å‹ - ä¸»è¦æ¨è
[models.economy]
name = "economy"
strategy = "weighted_random"
enabled = true

[[models.economy.backends]]
provider = "cheap_proxy"
model = "gpt-3.5-turbo"
weight = 0.8  # 80%ä½¿ç”¨ä¾¿å®œæœåŠ¡
priority = 1
enabled = true

[[models.economy.backends]]
provider = "medium_proxy"
model = "gpt-3.5-turbo"
weight = 0.15  # 15%ä½¿ç”¨ä¸­ç­‰ä»·æ ¼
priority = 2
enabled = true

[[models.economy.backends]]
provider = "official_backup"
model = "gpt-3.5-turbo"
weight = 0.05  # 5%ä½¿ç”¨å®˜æ–¹æœåŠ¡
priority = 3
enabled = true

# é¢„ç®—èŠå¤©æ¨¡å‹
[models.budget_chat]
name = "budget-chat"
strategy = "weighted_failover"
enabled = true

[[models.budget_chat.backends]]
provider = "cheap_proxy"
model = "gpt-3.5-turbo"
weight = 0.9
priority = 1
enabled = true

[[models.budget_chat.backends]]
provider = "medium_proxy"
model = "gpt-3.5-turbo"
weight = 0.1
priority = 2
enabled = true

# ä¾¿å®œçš„åŠ©æ‰‹
[models.cheap_assistant]
name = "cheap-assistant"
strategy = "failover"
enabled = true

[[models.cheap_assistant.backends]]
provider = "cheap_proxy"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 1
enabled = true

[[models.cheap_assistant.backends]]
provider = "medium_proxy"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 2
enabled = true

[[models.cheap_assistant.backends]]
provider = "official_backup"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 3
enabled = true
```

## ğŸ§ª å¼€å‘æµ‹è¯•é…ç½®

### å¼€å‘ç¯å¢ƒé…ç½®

é€‚ç”¨äºå¼€å‘å’Œæµ‹è¯•ç¯å¢ƒï¼š

```toml
# config_development.toml
[settings]
health_check_interval_seconds = 60
request_timeout_seconds = 60  # å¼€å‘æ—¶å…è®¸æ›´é•¿è¶…æ—¶
max_retries = 1               # å¼€å‘æ—¶å¿«é€Ÿå¤±è´¥
circuit_breaker_failure_threshold = 20  # å®½æ¾çš„ç†”æ–­æ¡ä»¶
circuit_breaker_timeout_seconds = 30

# å¼€å‘è€…ç”¨æˆ·
[users.developer]
name = "Developer"
token = "dev-token-123"
allowed_models = []  # å¼€å‘è€…å¯ä»¥è®¿é—®æ‰€æœ‰æ¨¡å‹
enabled = true
tags = ["developer"]

# æµ‹è¯•ç”¨æˆ·
[users.tester]
name = "Tester"
token = "test-token-456"
allowed_models = ["test-model", "debug-chat"]
enabled = true
tags = ["tester"]

# ä¸´æ—¶ç¦ç”¨çš„ç”¨æˆ·ï¼ˆç”¨äºæµ‹è¯•ï¼‰
[users.disabled_user]
name = "Disabled Test User"
token = "disabled-token-789"
allowed_models = ["test-model"]
enabled = false
tags = ["disabled", "test"]

# å¼€å‘ç”¨çš„OpenAIè´¦æˆ·
[providers.dev_openai]
name = "Development OpenAI"
base_url = "https://api.openai.com/v1"
api_key = "sk-dev-key"
models = ["gpt-3.5-turbo", "gpt-4"]
enabled = true
timeout_seconds = 60
max_retries = 1

# æµ‹è¯•ç”¨çš„æ¨¡æ‹ŸæœåŠ¡
[providers.mock_service]
name = "Mock Service"
base_url = "http://localhost:8080/v1"  # æœ¬åœ°æ¨¡æ‹ŸæœåŠ¡
api_key = "mock-key"
models = ["mock-gpt-3.5", "mock-gpt-4"]
enabled = true
timeout_seconds = 10
max_retries = 1

# æµ‹è¯•æ¨¡å‹
[models.test_model]
name = "test-model"
strategy = "random"
enabled = true

[[models.test_model.backends]]
provider = "mock_service"
model = "mock-gpt-3.5"
weight = 1.0
priority = 1
enabled = true

# è°ƒè¯•èŠå¤©æ¨¡å‹
[models.debug_chat]
name = "debug-chat"
strategy = "failover"
enabled = true

[[models.debug_chat.backends]]
provider = "mock_service"
model = "mock-gpt-3.5"
weight = 1.0
priority = 1
enabled = true

[[models.debug_chat.backends]]
provider = "dev_openai"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 2
enabled = true

# å¼€å‘ç”¨GPT-3.5
[models.gpt_3_5_turbo]
name = "gpt-3.5-turbo"
strategy = "round_robin"
enabled = true

[[models.gpt_3_5_turbo.backends]]
provider = "dev_openai"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 1
enabled = true

[[models.gpt_3_5_turbo.backends]]
provider = "mock_service"
model = "mock-gpt-3.5"
weight = 1.0
priority = 2
enabled = true

# å¼€å‘ç”¨GPT-4
[models.gpt_4]
name = "gpt-4"
strategy = "failover"
enabled = true

[[models.gpt_4.backends]]
provider = "dev_openai"
model = "gpt-4"
weight = 1.0
priority = 1
enabled = true

[[models.gpt_4.backends]]
provider = "mock_service"
model = "mock-gpt-4"
weight = 1.0
priority = 2
enabled = true
```

## ğŸŒ å¤šåœ°åŸŸé…ç½®

### å…¨çƒåˆ†å¸ƒå¼é…ç½®

é€‚ç”¨äºéœ€è¦ä¸ºå…¨çƒç”¨æˆ·æä¾›ä½å»¶è¿ŸæœåŠ¡çš„åœºæ™¯ï¼š

```toml
# config_global.toml
[settings]
health_check_interval_seconds = 30
request_timeout_seconds = 30
max_retries = 3
circuit_breaker_failure_threshold = 5
circuit_breaker_timeout_seconds = 60

[users.global_admin]
name = "Global Administrator"
token = "global-admin-token-secure"
allowed_models = []
enabled = true

# ç¾å›½ä¸œéƒ¨Provider
[providers.us_east]
name = "US East OpenAI"
base_url = "https://api.openai.com/v1"
api_key = "sk-us-east-key"
models = ["gpt-4", "gpt-3.5-turbo"]
enabled = true
timeout_seconds = 25
max_retries = 3

# æ¬§æ´²Provider
[providers.eu_west]
name = "EU West Azure"
base_url = "https://eu-west.openai.azure.com"
api_key = "eu-west-azure-key"
models = ["gpt-4", "gpt-35-turbo"]
enabled = true
timeout_seconds = 30
max_retries = 3
[providers.eu_west.headers]
"api-version" = "2024-02-01"

# äºšå¤ªProvider
[providers.apac]
name = "APAC Proxy Service"
base_url = "https://apac-proxy.example.com/v1"
api_key = "apac-proxy-key"
models = ["gpt-4", "gpt-3.5-turbo"]
enabled = true
timeout_seconds = 35
max_retries = 3

# å…¨çƒGPT-4æœåŠ¡ - ä½¿ç”¨æœ€ä½å»¶è¿Ÿç­–ç•¥
[models.global_gpt_4]
name = "gpt-4"
strategy = "least_latency"
enabled = true

[[models.global_gpt_4.backends]]
provider = "us_east"
model = "gpt-4"
weight = 1.0
priority = 1
enabled = true
tags = ["us", "americas"]

[[models.global_gpt_4.backends]]
provider = "eu_west"
model = "gpt-4"
weight = 1.0
priority = 2
enabled = true
tags = ["eu", "europe"]

[[models.global_gpt_4.backends]]
provider = "apac"
model = "gpt-4"
weight = 1.0
priority = 3
enabled = true
tags = ["apac", "asia"]

# å…¨çƒGPT-3.5æœåŠ¡
[models.global_gpt_3_5]
name = "gpt-3.5-turbo"
strategy = "least_latency"
enabled = true

[[models.global_gpt_3_5.backends]]
provider = "us_east"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 1
enabled = true

[[models.global_gpt_3_5.backends]]
provider = "eu_west"
model = "gpt-35-turbo"
weight = 1.0
priority = 2
enabled = true

[[models.global_gpt_3_5.backends]]
provider = "apac"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 3
enabled = true

# åœ°åŸŸä¼˜åŒ–çš„å¿«é€Ÿå“åº”æ¨¡å‹
[models.fast_global]
name = "fast-global"
strategy = "least_latency"
enabled = true

[[models.fast_global.backends]]
provider = "us_east"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 1
enabled = true

[[models.fast_global.backends]]
provider = "eu_west"
model = "gpt-35-turbo"
weight = 1.0
priority = 2
enabled = true

[[models.fast_global.backends]]
provider = "apac"
model = "gpt-3.5-turbo"
weight = 1.0
priority = 3
enabled = true
```

---

è¿™äº›é…ç½®ç¤ºä¾‹æ¶µç›–äº†å„ç§å¸¸è§çš„ä½¿ç”¨åœºæ™¯ã€‚æ‚¨å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„é…ç½®ä½œä¸ºèµ·ç‚¹ï¼Œç„¶åæ ¹æ®å®é™…æƒ…å†µè¿›è¡Œè°ƒæ•´ã€‚

è®°ä½åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼š
1. ä½¿ç”¨å¼ºéšæœºToken
2. å®šæœŸè½®æ¢APIå¯†é’¥
3. ç›‘æ§æœåŠ¡å¥åº·çŠ¶æ€
4. æ ¹æ®å®é™…æ€§èƒ½è°ƒæ•´æƒé‡å’Œè¶…æ—¶è®¾ç½®
