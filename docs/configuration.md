# âš™ï¸ é…ç½®æŒ‡å—

Berry API ä½¿ç”¨TOMLæ ¼å¼çš„é…ç½®æ–‡ä»¶ï¼Œä¸»è¦åŒ…å«4ä¸ªéƒ¨åˆ†ï¼š

```toml
[settings]        # å…¨å±€è®¾ç½®
[users.*]         # ç”¨æˆ·è®¤è¯é…ç½®
[providers.*]     # AIæœåŠ¡æä¾›å•†é…ç½®
[models.*]        # æ¨¡å‹æ˜ å°„é…ç½®
```

### âš™ï¸ å…¨å±€è®¾ç½® (settings)

```toml
[settings]
# åŸºç¡€è®¾ç½®
health_check_interval_seconds = 30    # å¥åº·æ£€æŸ¥é—´éš”
request_timeout_seconds = 30          # è¯·æ±‚è¶…æ—¶æ—¶é—´
max_retries = 3                       # æœ€å¤§é‡è¯•æ¬¡æ•°
max_internal_retries = 2              # å†…éƒ¨é‡è¯•æ¬¡æ•°
health_check_timeout_seconds = 10     # å¥åº·æ£€æŸ¥è¶…æ—¶

# ç†”æ–­å™¨è®¾ç½®
circuit_breaker_failure_threshold = 5 # ç†”æ–­å™¨å¤±è´¥é˜ˆå€¼
circuit_breaker_timeout_seconds = 60  # ç†”æ–­å™¨è¶…æ—¶æ—¶é—´
recovery_check_interval_seconds = 120 # æ¢å¤æ£€æŸ¥é—´éš”

# SmartAI è®¾ç½®ï¼ˆå¯é€‰ï¼‰
[settings.smart_ai]
initial_confidence = 0.8              # åˆå§‹ä¿¡å¿ƒåº¦
min_confidence = 0.05                 # æœ€å°ä¿¡å¿ƒåº¦
enable_time_decay = true              # å¯ç”¨æ—¶é—´è¡°å‡
exploration_ratio = 0.2               # æ¢ç´¢æµé‡æ¯”ä¾‹
```

### ğŸ‘¤ ç”¨æˆ·è®¤è¯é…ç½® (users)

```toml
# ç®¡ç†å‘˜ç”¨æˆ·
[users.admin]
name = "Administrator"
token = "berry-admin-token-12345"
allowed_models = []                   # ç©ºæ•°ç»„ = è®¿é—®æ‰€æœ‰æ¨¡å‹
enabled = true
tags = ["admin", "unlimited"]

# æ™®é€šç”¨æˆ·
[users.user1]
name = "Regular User"
token = "berry-user1-token-67890"
allowed_models = ["gpt-3.5-turbo"]   # é™åˆ¶è®¿é—®æ¨¡å‹
enabled = true
tags = ["user", "basic"]
# é€Ÿç‡é™åˆ¶ï¼ˆå¯é€‰ï¼‰
[users.user1.rate_limit]
requests_per_minute = 60
requests_per_hour = 1000

# é«˜çº§ç”¨æˆ·
[users.premium]
name = "Premium User"
token = "berry-premium-token-abcde"
allowed_models = ["gpt-4", "claude-3"]
enabled = true
tags = ["premium", "advanced"]
```

### ğŸ”Œ Provideré…ç½® (providers)

```toml
# OpenAI é…ç½®
[providers.openai]
name = "OpenAI"
base_url = "https://api.openai.com/v1"
api_key = "sk-your-openai-key-here"
models = ["gpt-4", "gpt-3.5-turbo"]
enabled = true
timeout_seconds = 30
backend_type = "openai"               # åç«¯ç±»å‹

# Azure OpenAI é…ç½®
[providers.azure]
name = "Azure OpenAI"
base_url = "https://your-resource.openai.azure.com"
api_key = "your-azure-key-here"
models = ["gpt-4", "gpt-35-turbo"]
enabled = true
backend_type = "openai"
# è‡ªå®šä¹‰è¯·æ±‚å¤´
[providers.azure.headers]
"api-version" = "2024-02-01"

# Anthropic Claude é…ç½®
[providers.anthropic]
name = "Anthropic"
base_url = "https://api.anthropic.com"
api_key = "sk-ant-your-key-here"
models = ["claude-3-opus", "claude-3-sonnet"]
enabled = true
backend_type = "claude"               # Claudeæ ¼å¼
```

### ğŸ¯ æ¨¡å‹æ˜ å°„é…ç½® (models)

```toml
# åŸºç¡€æ¨¡å‹é…ç½®
[models.gpt_4]
name = "gpt-4"                        # å¯¹å¤–æš´éœ²çš„æ¨¡å‹å
strategy = "weighted_failover"        # è´Ÿè½½å‡è¡¡ç­–ç•¥
enabled = true

# åç«¯é…ç½® - ä¸»è¦æœåŠ¡
[[models.gpt_4.backends]]
provider = "openai"
model = "gpt-4"
weight = 0.7                          # 70% æƒé‡
priority = 1                          # æœ€é«˜ä¼˜å…ˆçº§
enabled = true
billing_mode = "per_token"            # è®¡è´¹æ¨¡å¼
tags = ["premium"]

# åç«¯é…ç½® - å¤‡ç”¨æœåŠ¡
[[models.gpt_4.backends]]
provider = "azure"
model = "gpt-4"
weight = 0.3                          # 30% æƒé‡
priority = 2                          # å¤‡ç”¨ä¼˜å…ˆçº§
enabled = true
billing_mode = "per_token"
tags = ["enterprise"]
```

### ğŸ“‹ é…ç½®æ–‡ä»¶æ¨¡æ¿

Berry API æä¾›äº†å¤šä¸ªé…ç½®æ–‡ä»¶æ¨¡æ¿ï¼š

**1. å®Œæ•´é…ç½®ç¤ºä¾‹ (`config-example.toml`)**
- âœ… åŒ…å«æ‰€æœ‰é…ç½®é€‰é¡¹å’Œè¯¦ç»†æ³¨é‡Š
- âœ… 8ç§è´Ÿè½½å‡è¡¡ç­–ç•¥ç¤ºä¾‹
- âœ… å¤šç§ç”¨æˆ·æƒé™é…ç½®
- âœ… å®Œæ•´çš„Provideré…ç½®ç¤ºä¾‹
- âœ… å®‰å…¨å’Œæ€§èƒ½ä¼˜åŒ–å»ºè®®

**2. SmartAIä¸“ç”¨é…ç½® (`smart_ai_example.toml`)**
- âœ… SmartAIç­–ç•¥ä¸“ç”¨é…ç½®
- âœ… æˆæœ¬æ„ŸçŸ¥è´Ÿè½½å‡è¡¡
- âœ… å°æµé‡å¥åº·æ£€æŸ¥ä¼˜åŒ–
- âœ… ä¿¡å¿ƒåº¦è°ƒæ•´å‚æ•°

**ä½¿ç”¨æ–¹æ³•**ï¼š

```bash
# ä½¿ç”¨å®Œæ•´é…ç½®æ¨¡æ¿
cp config-example.toml config.toml

# ä½¿ç”¨SmartAIé…ç½®æ¨¡æ¿
cp smart_ai_example.toml config.toml

# ç¼–è¾‘é…ç½®æ–‡ä»¶
vim config.toml
```
