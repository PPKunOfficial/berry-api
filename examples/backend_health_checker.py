#!/usr/bin/env python3
"""
åç«¯å¥åº·æ£€æŸ¥å·¥å…·
ä½¿ç”¨backendå‚æ•°ç›´æ¥æµ‹è¯•å„ä¸ªåç«¯çš„å¯ç”¨æ€§
"""

import requests
import json
import time
import argparse
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

class BackendHealthChecker:
    def __init__(self, base_url: str = "http://localhost:3000", auth_token: str = "test-token"):
        self.base_url = base_url
        self.auth_token = auth_token
        self.session = requests.Session()
        self.session.headers.update({
            "Content-Type": "application/json",
            "Authorization": f"Bearer {auth_token}"
        })
    
    def get_available_backends(self) -> List[str]:
        """è·å–å¯ç”¨çš„åç«¯åˆ—è¡¨"""
        try:
            response = self.session.get(f"{self.base_url}/smart-ai/weights")
            if response.status_code == 200:
                data = response.json()
                backends = set()
                for model in data.get("models", []):
                    for backend in model.get("backends", []):
                        if backend.get("enabled", False):
                            backends.add(backend["provider"])
                return sorted(list(backends))
        except Exception as e:
            print(f"âš ï¸  æ— æ³•è·å–åç«¯åˆ—è¡¨: {e}")
        
        # è¿”å›é»˜è®¤åç«¯åˆ—è¡¨
        return ["openai_official", "anthropic_claude", "google_gemini"]
    
    def get_available_models(self) -> List[str]:
        """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        try:
            response = self.session.get(f"{self.base_url}/models")
            if response.status_code == 200:
                data = response.json()
                return [model["id"] for model in data.get("data", [])]
        except Exception as e:
            print(f"âš ï¸  æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨: {e}")
        
        return ["gpt-4o", "claude-sonnet-4"]
    
    def check_backend_health(
        self, 
        backend: str, 
        model: str = "gpt-4o", 
        timeout: int = 30,
        test_streaming: bool = False
    ) -> Dict:
        """æ£€æŸ¥å•ä¸ªåç«¯çš„å¥åº·çŠ¶æ€"""
        start_time = time.time()
        
        payload = {
            "model": model,
            "messages": [{"role": "user", "content": "ping"}],
            "backend": backend,
            "max_tokens": 5,
            "stream": test_streaming
        }
        
        try:
            response = self.session.post(
                f"{self.base_url}/v1/chat/completions",
                json=payload,
                timeout=timeout,
                stream=test_streaming
            )
            
            response_time = time.time() - start_time
            
            if response.status_code == 200:
                if test_streaming:
                    # å¯¹äºæµå¼è¯·æ±‚ï¼Œè¯»å–ç¬¬ä¸€ä¸ªæ•°æ®å—
                    try:
                        first_chunk = next(response.iter_lines(decode_unicode=True))
                        return {
                            "status": "healthy",
                            "backend": backend,
                            "model": model,
                            "response_time": response_time,
                            "http_status": response.status_code,
                            "streaming": True,
                            "first_chunk": first_chunk[:100] if first_chunk else None
                        }
                    except Exception as e:
                        return {
                            "status": "unhealthy",
                            "backend": backend,
                            "model": model,
                            "response_time": response_time,
                            "http_status": response.status_code,
                            "error": f"Streaming error: {e}",
                            "streaming": True
                        }
                else:
                    # éæµå¼è¯·æ±‚
                    data = response.json()
                    content = data.get("choices", [{}])[0].get("message", {}).get("content", "")
                    return {
                        "status": "healthy",
                        "backend": backend,
                        "model": model,
                        "response_time": response_time,
                        "http_status": response.status_code,
                        "content": content[:50] if content else None,
                        "streaming": False
                    }
            else:
                return {
                    "status": "unhealthy",
                    "backend": backend,
                    "model": model,
                    "response_time": response_time,
                    "http_status": response.status_code,
                    "error": response.text[:200],
                    "streaming": test_streaming
                }
                
        except requests.exceptions.Timeout:
            return {
                "status": "timeout",
                "backend": backend,
                "model": model,
                "response_time": timeout,
                "error": "Request timeout",
                "streaming": test_streaming
            }
        except Exception as e:
            return {
                "status": "error",
                "backend": backend,
                "model": model,
                "response_time": time.time() - start_time,
                "error": str(e),
                "streaming": test_streaming
            }
    
    def check_all_backends(
        self, 
        backends: Optional[List[str]] = None,
        model: str = "gpt-4o",
        timeout: int = 30,
        test_streaming: bool = False,
        parallel: bool = True
    ) -> List[Dict]:
        """æ£€æŸ¥æ‰€æœ‰åç«¯çš„å¥åº·çŠ¶æ€"""
        if backends is None:
            backends = self.get_available_backends()
        
        print(f"ğŸ¥ æ£€æŸ¥ {len(backends)} ä¸ªåç«¯çš„å¥åº·çŠ¶æ€...")
        print(f"æ¨¡å‹: {model}")
        print(f"è¶…æ—¶: {timeout}s")
        print(f"æµå¼æµ‹è¯•: {'æ˜¯' if test_streaming else 'å¦'}")
        print(f"å¹¶è¡Œæ£€æŸ¥: {'æ˜¯' if parallel else 'å¦'}")
        print("-" * 50)
        
        results = []
        
        if parallel:
            # å¹¶è¡Œæ£€æŸ¥
            with ThreadPoolExecutor(max_workers=5) as executor:
                future_to_backend = {
                    executor.submit(
                        self.check_backend_health, 
                        backend, 
                        model, 
                        timeout, 
                        test_streaming
                    ): backend 
                    for backend in backends
                }
                
                for future in as_completed(future_to_backend):
                    result = future.result()
                    results.append(result)
                    self._print_result(result)
        else:
            # ä¸²è¡Œæ£€æŸ¥
            for backend in backends:
                result = self.check_backend_health(backend, model, timeout, test_streaming)
                results.append(result)
                self._print_result(result)
        
        return results
    
    def _print_result(self, result: Dict):
        """æ‰“å°å•ä¸ªæ£€æŸ¥ç»“æœ"""
        backend = result["backend"]
        status = result["status"]
        response_time = result.get("response_time", 0)
        
        if status == "healthy":
            print(f"âœ… {backend}: å¥åº· ({response_time:.2f}s)")
            if result.get("content"):
                print(f"   å“åº”: {result['content']}")
            elif result.get("first_chunk"):
                print(f"   é¦–å—: {result['first_chunk']}")
        elif status == "unhealthy":
            http_status = result.get("http_status", "N/A")
            print(f"âŒ {backend}: ä¸å¥åº· (HTTP {http_status}, {response_time:.2f}s)")
            if result.get("error"):
                print(f"   é”™è¯¯: {result['error']}")
        elif status == "timeout":
            print(f"â° {backend}: è¶…æ—¶ ({response_time:.2f}s)")
        else:
            print(f"ğŸ”¥ {backend}: é”™è¯¯ ({response_time:.2f}s)")
            if result.get("error"):
                print(f"   é”™è¯¯: {result['error']}")
    
    def continuous_monitoring(
        self, 
        backends: Optional[List[str]] = None,
        model: str = "gpt-4o",
        interval: int = 60,
        timeout: int = 30
    ):
        """æŒç»­ç›‘æ§åç«¯å¥åº·çŠ¶æ€"""
        if backends is None:
            backends = self.get_available_backends()
        
        print(f"ğŸ”„ å¼€å§‹æŒç»­ç›‘æ§ {len(backends)} ä¸ªåç«¯")
        print(f"æ£€æŸ¥é—´éš”: {interval}s")
        print(f"æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
        print("=" * 60)
        
        try:
            while True:
                timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                print(f"\nâ° {timestamp}")
                
                results = self.check_all_backends(
                    backends, model, timeout, parallel=True
                )
                
                # ç»Ÿè®¡
                healthy_count = sum(1 for r in results if r["status"] == "healthy")
                total_count = len(results)
                
                print(f"\nğŸ“Š ç»Ÿè®¡: {healthy_count}/{total_count} ä¸ªåç«¯å¥åº·")
                
                if healthy_count < total_count:
                    unhealthy = [r["backend"] for r in results if r["status"] != "healthy"]
                    print(f"ğŸš¨ ä¸å¥åº·çš„åç«¯: {', '.join(unhealthy)}")
                
                print(f"\nğŸ’¤ ç­‰å¾… {interval} ç§’...")
                time.sleep(interval)
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç›‘æ§å·²åœæ­¢")
    
    def benchmark_backends(
        self, 
        backends: Optional[List[str]] = None,
        model: str = "gpt-4o",
        rounds: int = 3
    ):
        """å¯¹åç«¯è¿›è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
        if backends is None:
            backends = self.get_available_backends()
        
        print(f"ğŸƒ å¯¹ {len(backends)} ä¸ªåç«¯è¿›è¡Œæ€§èƒ½æµ‹è¯•")
        print(f"æµ‹è¯•è½®æ•°: {rounds}")
        print("=" * 50)
        
        all_results = {}
        
        for round_num in range(1, rounds + 1):
            print(f"\nğŸ”„ ç¬¬ {round_num} è½®æµ‹è¯•")
            print("-" * 30)
            
            results = self.check_all_backends(
                backends, model, timeout=30, parallel=False
            )
            
            for result in results:
                backend = result["backend"]
                if backend not in all_results:
                    all_results[backend] = []
                all_results[backend].append(result)
            
            if round_num < rounds:
                print("â³ ç­‰å¾… 5 ç§’...")
                time.sleep(5)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š æ€§èƒ½ç»Ÿè®¡ ({rounds} è½®)")
        print("=" * 50)
        
        for backend in sorted(all_results.keys()):
            results = all_results[backend]
            healthy_results = [r for r in results if r["status"] == "healthy"]
            
            if healthy_results:
                response_times = [r["response_time"] for r in healthy_results]
                avg_time = sum(response_times) / len(response_times)
                min_time = min(response_times)
                max_time = max(response_times)
                success_rate = len(healthy_results) / len(results) * 100
                
                print(f"âœ… {backend}:")
                print(f"   æˆåŠŸç‡: {success_rate:.1f}%")
                print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_time:.2f}s")
                print(f"   æœ€å¿«å“åº”: {min_time:.2f}s")
                print(f"   æœ€æ…¢å“åº”: {max_time:.2f}s")
            else:
                print(f"âŒ {backend}: æ‰€æœ‰æµ‹è¯•éƒ½å¤±è´¥")
            print()

def main():
    parser = argparse.ArgumentParser(description="åç«¯å¥åº·æ£€æŸ¥å·¥å…·")
    parser.add_argument("--url", default="http://localhost:3000", help="APIåŸºç¡€URL")
    parser.add_argument("--token", default="test-token", help="è®¤è¯ä»¤ç‰Œ")
    parser.add_argument("--model", default="gpt-4o", help="æµ‹è¯•æ¨¡å‹")
    parser.add_argument("--timeout", type=int, default=30, help="è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)")
    parser.add_argument("--backends", nargs="+", help="æŒ‡å®šè¦æµ‹è¯•çš„åç«¯")
    
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
    
    # å•æ¬¡æ£€æŸ¥
    check_parser = subparsers.add_parser("check", help="å•æ¬¡å¥åº·æ£€æŸ¥")
    check_parser.add_argument("--streaming", action="store_true", help="æµ‹è¯•æµå¼è¯·æ±‚")
    check_parser.add_argument("--serial", action="store_true", help="ä¸²è¡Œæ£€æŸ¥ï¼ˆéå¹¶è¡Œï¼‰")
    
    # æŒç»­ç›‘æ§
    monitor_parser = subparsers.add_parser("monitor", help="æŒç»­ç›‘æ§")
    monitor_parser.add_argument("--interval", type=int, default=60, help="æ£€æŸ¥é—´éš”(ç§’)")
    
    # æ€§èƒ½æµ‹è¯•
    benchmark_parser = subparsers.add_parser("benchmark", help="æ€§èƒ½åŸºå‡†æµ‹è¯•")
    benchmark_parser.add_argument("--rounds", type=int, default=3, help="æµ‹è¯•è½®æ•°")
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    checker = BackendHealthChecker(args.url, args.token)
    
    if args.command == "check":
        checker.check_all_backends(
            backends=args.backends,
            model=args.model,
            timeout=args.timeout,
            test_streaming=args.streaming,
            parallel=not args.serial
        )
    elif args.command == "monitor":
        checker.continuous_monitoring(
            backends=args.backends,
            model=args.model,
            interval=args.interval,
            timeout=args.timeout
        )
    elif args.command == "benchmark":
        checker.benchmark_backends(
            backends=args.backends,
            model=args.model,
            rounds=args.rounds
        )

if __name__ == "__main__":
    main()
