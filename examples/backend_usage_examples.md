# åç«¯æŒ‡å®šåŠŸèƒ½ä½¿ç”¨ç¤ºä¾‹

## å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬ç”¨æ³•

```bash
# æ­£å¸¸è¯·æ±‚ï¼ˆè‡ªåŠ¨è´Ÿè½½å‡è¡¡ï¼‰
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-token" \
  -d '{
    "model": "gpt-4o",
    "messages": [{"role": "user", "content": "Hello"}]
  }'

# æŒ‡å®šåç«¯è¯·æ±‚
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-token" \
  -d '{
    "model": "gpt-4o",
    "messages": [{"role": "user", "content": "Hello"}],
    "backend": "openai_official"
  }'
```

### 2. å¥åº·æ£€æŸ¥

```bash
# æ£€æŸ¥ç‰¹å®šåç«¯
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-token" \
  -d '{
    "model": "gpt-4o",
    "messages": [{"role": "user", "content": "ping"}],
    "backend": "openai_official",
    "max_tokens": 1
  }'
```

### 3. æµå¼æµ‹è¯•

```bash
# æµ‹è¯•æµå¼å“åº”
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-token" \
  -d '{
    "model": "gpt-4o",
    "messages": [{"role": "user", "content": "Count to 5"}],
    "backend": "openai_official",
    "stream": true,
    "max_tokens": 50
  }' \
  --no-buffer
```

## è„šæœ¬å·¥å…·

### 1. Bash å¥åº·æ£€æŸ¥è„šæœ¬

```bash
#!/bin/bash
# health_check.sh

BACKENDS=("openai_official" "anthropic_claude" "google_gemini")
MODEL="gpt-4o"
BASE_URL="http://localhost:3000"
TOKEN="your-token"

echo "ğŸ¥ åç«¯å¥åº·æ£€æŸ¥æŠ¥å‘Š"
echo "==================="
echo "æ—¶é—´: $(date)"
echo "æ¨¡å‹: $MODEL"
echo

for backend in "${BACKENDS[@]}"; do
    echo "æ£€æŸ¥åç«¯: $backend"
    
    start_time=$(date +%s.%N)
    response=$(curl -s -w "HTTPSTATUS:%{http_code}" \
      -X POST "$BASE_URL/v1/chat/completions" \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $TOKEN" \
      -d "{
        \"model\": \"$MODEL\",
        \"messages\": [{\"role\": \"user\", \"content\": \"ping\"}],
        \"backend\": \"$backend\",
        \"max_tokens\": 1
      }")
    end_time=$(date +%s.%N)
    
    http_status=$(echo "$response" | grep -o "HTTPSTATUS:[0-9]*" | cut -d: -f2)
    response_time=$(echo "$end_time - $start_time" | bc)
    
    if [ "$http_status" = "200" ]; then
        echo "âœ… $backend: å¥åº· (${response_time}s)"
    else
        echo "âŒ $backend: ä¸å¥åº· (HTTP $http_status)"
    fi
    echo
done
```

### 2. Python ç›‘æ§å·¥å…·

```python
# ä½¿ç”¨æˆ‘ä»¬æä¾›çš„ backend_health_checker.py

# å•æ¬¡æ£€æŸ¥æ‰€æœ‰åç«¯
python3 examples/backend_health_checker.py check

# æ£€æŸ¥ç‰¹å®šåç«¯
python3 examples/backend_health_checker.py check --backends openai_official anthropic_claude

# æµ‹è¯•æµå¼è¯·æ±‚
python3 examples/backend_health_checker.py check --streaming

# æŒç»­ç›‘æ§ï¼ˆæ¯60ç§’æ£€æŸ¥ä¸€æ¬¡ï¼‰
python3 examples/backend_health_checker.py monitor --interval 60

# æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼ˆ3è½®ï¼‰
python3 examples/backend_health_checker.py benchmark --rounds 3
```

## æ•…éšœæ’é™¤åœºæ™¯

### 1. è°ƒè¯•ç‰¹å®šåç«¯é—®é¢˜

```bash
# å½“æŸä¸ªåç«¯å‡ºç°é—®é¢˜æ—¶ï¼Œç›´æ¥æµ‹è¯•è¯¥åç«¯
curl -v -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-token" \
  -d '{
    "model": "gpt-4o",
    "messages": [{"role": "user", "content": "test"}],
    "backend": "problematic_backend",
    "max_tokens": 5
  }'
```

### 2. æ¯”è¾ƒä¸åŒåç«¯çš„å“åº”

```bash
# æµ‹è¯•å¤šä¸ªåç«¯çš„ç›¸åŒè¯·æ±‚
for backend in openai_official anthropic_claude; do
    echo "Testing $backend:"
    curl -s -X POST http://localhost:3000/v1/chat/completions \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer your-token" \
      -d "{
        \"model\": \"gpt-4o\",
        \"messages\": [{\"role\": \"user\", \"content\": \"What is 2+2?\"}],
        \"backend\": \"$backend\",
        \"max_tokens\": 10
      }" | jq '.choices[0].message.content'
    echo
done
```

### 3. æ€§èƒ½å¯¹æ¯”æµ‹è¯•

```bash
# æµ‹è¯•å“åº”æ—¶é—´
for backend in openai_official anthropic_claude; do
    echo "Performance test for $backend:"
    time curl -s -X POST http://localhost:3000/v1/chat/completions \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer your-token" \
      -d "{
        \"model\": \"gpt-4o\",
        \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],
        \"backend\": \"$backend\",
        \"max_tokens\": 5
      }" > /dev/null
    echo
done
```

## ç›‘æ§é›†æˆ

### 1. Prometheus æŒ‡æ ‡æ”¶é›†

```python
import requests
import time
from prometheus_client import Gauge, start_http_server

# åˆ›å»ºæŒ‡æ ‡
backend_health_gauge = Gauge('backend_health', 'Backend health status', ['backend', 'model'])
backend_response_time_gauge = Gauge('backend_response_time_seconds', 'Backend response time', ['backend', 'model'])

def collect_metrics():
    backends = ["openai_official", "anthropic_claude"]
    model = "gpt-4o"
    
    for backend in backends:
        start_time = time.time()
        try:
            response = requests.post(
                "http://localhost:3000/v1/chat/completions",
                headers={
                    "Content-Type": "application/json",
                    "Authorization": "Bearer your-token"
                },
                json={
                    "model": model,
                    "messages": [{"role": "user", "content": "ping"}],
                    "backend": backend,
                    "max_tokens": 1
                },
                timeout=30
            )
            
            response_time = time.time() - start_time
            health_status = 1 if response.status_code == 200 else 0
            
            backend_health_gauge.labels(backend=backend, model=model).set(health_status)
            backend_response_time_gauge.labels(backend=backend, model=model).set(response_time)
            
        except Exception as e:
            backend_health_gauge.labels(backend=backend, model=model).set(0)
            backend_response_time_gauge.labels(backend=backend, model=model).set(0)

# å¯åŠ¨æŒ‡æ ‡æœåŠ¡å™¨
start_http_server(8000)

# å®šæœŸæ”¶é›†æŒ‡æ ‡
while True:
    collect_metrics()
    time.sleep(60)
```

### 2. å‘Šè­¦è„šæœ¬

```bash
#!/bin/bash
# alert_check.sh

WEBHOOK_URL="https://hooks.slack.com/your/webhook/url"
BACKENDS=("openai_official" "anthropic_claude")
MODEL="gpt-4o"

for backend in "${BACKENDS[@]}"; do
    response=$(curl -s -w "HTTPSTATUS:%{http_code}" \
      -X POST "http://localhost:3000/v1/chat/completions" \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer your-token" \
      -d "{
        \"model\": \"$MODEL\",
        \"messages\": [{\"role\": \"user\", \"content\": \"ping\"}],
        \"backend\": \"$backend\",
        \"max_tokens\": 1
      }")
    
    http_status=$(echo "$response" | grep -o "HTTPSTATUS:[0-9]*" | cut -d: -f2)
    
    if [ "$http_status" != "200" ]; then
        # å‘é€å‘Šè­¦
        curl -X POST "$WEBHOOK_URL" \
          -H "Content-Type: application/json" \
          -d "{
            \"text\": \"ğŸš¨ Backend Alert: $backend is unhealthy (HTTP $http_status)\"
          }"
    fi
done
```

## æœ€ä½³å®è·µ

### 1. ç”Ÿäº§ç¯å¢ƒä½¿ç”¨

- âœ… ç”¨äºå¥åº·æ£€æŸ¥å’Œç›‘æ§
- âœ… ç”¨äºæ•…éšœæ’é™¤å’Œè°ƒè¯•
- âœ… ç”¨äºæ€§èƒ½æµ‹è¯•å’Œå¯¹æ¯”
- âš ï¸ é¿å…åœ¨æ­£å¸¸ä¸šåŠ¡è¯·æ±‚ä¸­ä½¿ç”¨
- âš ï¸ ä¸è¦ä¾èµ–ç‰¹å®šåç«¯è¿›è¡Œä¸šåŠ¡é€»è¾‘

### 2. å®‰å…¨è€ƒè™‘

- ğŸ”’ `backend` å‚æ•°ä¸ä¼šä¼ é€’ç»™ä¸Šæ¸¸API
- ğŸ”’ åªèƒ½é€‰æ‹©é…ç½®æ–‡ä»¶ä¸­å·²å®šä¹‰çš„åç«¯
- ğŸ”’ æ‰€æœ‰è¯·æ±‚éƒ½ä¼šè¢«è®°å½•åœ¨æ—¥å¿—ä¸­
- ğŸ”’ ä¸ç»•è¿‡ç”¨æˆ·æƒé™æ£€æŸ¥

### 3. ç›‘æ§å»ºè®®

- ğŸ“Š å®šæœŸæ£€æŸ¥æ‰€æœ‰åç«¯çš„å¥åº·çŠ¶æ€
- ğŸ“Š ç›‘æ§å“åº”æ—¶é—´å’ŒæˆåŠŸç‡
- ğŸ“Š è®¾ç½®å‘Šè­¦é˜ˆå€¼
- ğŸ“Š è®°å½•å†å²æ•°æ®ç”¨äºåˆ†æ

### 4. è°ƒè¯•æŠ€å·§

- ğŸ” ä½¿ç”¨ `RUST_LOG=debug` æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
- ğŸ” æ¯”è¾ƒä¸åŒåç«¯çš„å“åº”å·®å¼‚
- ğŸ” æµ‹è¯•æµå¼å’Œéæµå¼è¯·æ±‚
- ğŸ” æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIå¯†é’¥é…ç½®

è¿™ä¸ªåŠŸèƒ½ä¸ºè¿ç»´å’Œå¼€å‘æä¾›äº†å¼ºå¤§çš„å·¥å…·ï¼Œå¸®åŠ©æ‚¨æ›´å¥½åœ°ç®¡ç†å’Œç›‘æ§å¤šåç«¯ç³»ç»Ÿã€‚
